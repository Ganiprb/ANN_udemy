{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('House_Price.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Characteristics:\n",
    "\n",
    "##### Number of Instances:\n",
    " \t\n",
    "20640\n",
    "\n",
    "##### Number of Attributes:\n",
    " \t\n",
    "8 numeric, predictive attributes and the target\n",
    "\n",
    "##### Attribute Information:\n",
    " \t\n",
    "* MedInc median income in block\n",
    "* HouseAge median house age in block\n",
    "* AveRooms average number of rooms\n",
    "* AveBedrms average number of bedrooms\n",
    "* Population block population\n",
    "* AveOccup average house occupancy\n",
    "* Latitude house block latitude\n",
    "* Longitude house block longitude\n",
    "\n",
    "#### Target\n",
    "\n",
    "The target variable is the median house value in units of 100,000 for California districts.\n",
    "\n",
    "#### Documentation \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#examples-using-sklearn-datasets-fetch-california-housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price', 'resid_area', 'air_qual', 'room_num', 'age', 'dist1', 'dist2',\n",
      "       'dist3', 'dist4', 'teachers', 'poor_prop', 'airport', 'n_hos_beds',\n",
      "       'n_hot_rooms', 'waterbody', 'rainfall', 'bus_ter', 'parks', 'Sold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.528854</td>\n",
       "      <td>41.136779</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.971996</td>\n",
       "      <td>3.628775</td>\n",
       "      <td>3.960672</td>\n",
       "      <td>3.618972</td>\n",
       "      <td>21.544466</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>7.899767</td>\n",
       "      <td>13.041605</td>\n",
       "      <td>39.181818</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.182176</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.108532</td>\n",
       "      <td>2.108580</td>\n",
       "      <td>2.119797</td>\n",
       "      <td>2.099203</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>1.476683</td>\n",
       "      <td>5.238957</td>\n",
       "      <td>12.513697</td>\n",
       "      <td>0.010632</td>\n",
       "      <td>0.498422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.460000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.268000</td>\n",
       "      <td>10.057600</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "      <td>35.190000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>2.232500</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>6.634500</td>\n",
       "      <td>11.189800</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.046464</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "      <td>39.690000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.385000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>7.999000</td>\n",
       "      <td>12.720000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.053507</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.367500</td>\n",
       "      <td>4.992500</td>\n",
       "      <td>5.407500</td>\n",
       "      <td>4.985000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>9.088000</td>\n",
       "      <td>14.170800</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>57.740000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.320000</td>\n",
       "      <td>11.930000</td>\n",
       "      <td>12.320000</td>\n",
       "      <td>11.940000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>10.876000</td>\n",
       "      <td>101.120000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price  resid_area    air_qual    room_num         age       dist1  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    22.528854   41.136779    0.554695    6.284634   68.574901    3.971996   \n",
       "std      9.182176    6.860353    0.115878    0.702617   28.148861    2.108532   \n",
       "min      5.000000   30.460000    0.385000    3.561000    2.900000    1.130000   \n",
       "25%     17.025000   35.190000    0.449000    5.885500   45.025000    2.270000   \n",
       "50%     21.200000   39.690000    0.538000    6.208500   77.500000    3.385000   \n",
       "75%     25.000000   48.100000    0.624000    6.623500   94.075000    5.367500   \n",
       "max     50.000000   57.740000    0.871000    8.780000  100.000000   12.320000   \n",
       "\n",
       "            dist2       dist3       dist4    teachers   poor_prop  n_hos_beds  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  498.000000   \n",
       "mean     3.628775    3.960672    3.618972   21.544466   12.653063    7.899767   \n",
       "std      2.108580    2.119797    2.099203    2.164946    7.141062    1.476683   \n",
       "min      0.920000    1.150000    0.730000   18.000000    1.730000    5.268000   \n",
       "25%      1.940000    2.232500    1.940000   19.800000    6.950000    6.634500   \n",
       "50%      3.010000    3.375000    3.070000   20.950000   11.360000    7.999000   \n",
       "75%      4.992500    5.407500    4.985000   22.600000   16.955000    9.088000   \n",
       "max     11.930000   12.320000   11.940000   27.400000   37.970000   10.876000   \n",
       "\n",
       "       n_hot_rooms    rainfall       parks        Sold  \n",
       "count   506.000000  506.000000  506.000000  506.000000  \n",
       "mean     13.041605   39.181818    0.054454    0.454545  \n",
       "std       5.238957   12.513697    0.010632    0.498422  \n",
       "min      10.057600    3.000000    0.033292    0.000000  \n",
       "25%      11.189800   28.000000    0.046464    0.000000  \n",
       "50%      12.720000   39.000000    0.053507    0.000000  \n",
       "75%      14.170800   50.000000    0.061397    1.000000  \n",
       "max     101.120000   60.000000    0.086711    1.000000  "
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NYARI PENCILAN\n",
    "fig,ax=plt.subplots()\n",
    "ax.scatter(df.n_hot_rooms,df.Sold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.scatter(df.parks,df.Sold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=np.percentile(df.n_hot_rooms,[99])[0]\n",
    "pr2=np.percentile(df.rainfall,[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.n_hot_rooms[df.n_hot_rooms>3*pr]=3*pr #nilai max ketinggian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.rainfall[df.rainfall<0.3*pr2]=0.3*pr2 #nilai min kerendahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.399519999999999, 20.0)"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr,pr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>airport</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>bus_ter</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.97</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.394</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>13.4</td>\n",
       "      <td>48.10</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.87</td>\n",
       "      <td>19.8</td>\n",
       "      <td>23.29</td>\n",
       "      <td>NO</td>\n",
       "      <td>8.268</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>Lake</td>\n",
       "      <td>29</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.063344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  resid_area  air_qual  room_num   age  dist1  dist2  dist3  dist4  \\\n",
       "2     34.7       37.07     0.469     7.185  61.1   5.03   4.86   5.01   4.97   \n",
       "423   13.4       48.10     0.614     6.103  85.1   2.08   1.80   2.34   1.87   \n",
       "\n",
       "     teachers  poor_prop airport  n_hos_beds  n_hot_rooms waterbody  rainfall  \\\n",
       "2        22.2       4.03      NO       7.394     46.19856      None        38   \n",
       "423      19.8      23.29      NO       8.268     46.19856      Lake        29   \n",
       "\n",
       "    bus_ter     parks  Sold  \n",
       "2       YES  0.045764     0  \n",
       "423     YES  0.063344     0  "
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.n_hot_rooms>=3*pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>airport</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>bus_ter</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>28.1</td>\n",
       "      <td>40.59</td>\n",
       "      <td>0.489</td>\n",
       "      <td>6.375</td>\n",
       "      <td>32.3</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.57</td>\n",
       "      <td>21.4</td>\n",
       "      <td>9.38</td>\n",
       "      <td>YES</td>\n",
       "      <td>7.562</td>\n",
       "      <td>10.2248</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.044019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  resid_area  air_qual  room_num   age  dist1  dist2  dist3  dist4  \\\n",
       "213   28.1       40.59     0.489     6.375  32.3   4.11   3.92   4.18   3.57   \n",
       "\n",
       "     teachers  poor_prop airport  n_hos_beds  n_hot_rooms waterbody  rainfall  \\\n",
       "213      21.4       9.38     YES       7.562      10.2248      None         6   \n",
       "\n",
       "    bus_ter     parks  Sold  \n",
       "213     YES  0.044019     1  "
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.rainfall<=0.3*pr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   price        506 non-null    float64\n",
      " 1   resid_area   506 non-null    float64\n",
      " 2   air_qual     506 non-null    float64\n",
      " 3   room_num     506 non-null    float64\n",
      " 4   age          506 non-null    float64\n",
      " 5   dist1        506 non-null    float64\n",
      " 6   dist2        506 non-null    float64\n",
      " 7   dist3        506 non-null    float64\n",
      " 8   dist4        506 non-null    float64\n",
      " 9   teachers     506 non-null    float64\n",
      " 10  poor_prop    506 non-null    float64\n",
      " 11  airport      506 non-null    object \n",
      " 12  n_hos_beds   498 non-null    float64\n",
      " 13  n_hot_rooms  506 non-null    float64\n",
      " 14  waterbody    506 non-null    object \n",
      " 15  rainfall     506 non-null    int64  \n",
      " 16  bus_ter      506 non-null    object \n",
      " 17  parks        506 non-null    float64\n",
      " 18  Sold         506 non-null    int64  \n",
      "dtypes: float64(14), int64(2), object(3)\n",
      "memory usage: 75.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n_hos_beds=df.n_hos_beds.fillna(df.n_hos_beds.mean()) #ngisi value kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   price        506 non-null    float64\n",
      " 1   resid_area   506 non-null    float64\n",
      " 2   air_qual     506 non-null    float64\n",
      " 3   room_num     506 non-null    float64\n",
      " 4   age          506 non-null    float64\n",
      " 5   dist1        506 non-null    float64\n",
      " 6   dist2        506 non-null    float64\n",
      " 7   dist3        506 non-null    float64\n",
      " 8   dist4        506 non-null    float64\n",
      " 9   teachers     506 non-null    float64\n",
      " 10  poor_prop    506 non-null    float64\n",
      " 11  airport      506 non-null    object \n",
      " 12  n_hos_beds   506 non-null    float64\n",
      " 13  n_hot_rooms  506 non-null    float64\n",
      " 14  waterbody    506 non-null    object \n",
      " 15  rainfall     506 non-null    int64  \n",
      " 16  bus_ter      506 non-null    object \n",
      " 17  parks        506 non-null    float64\n",
      " 18  Sold         506 non-null    int64  \n",
      "dtypes: float64(14), int64(2), object(3)\n",
      "memory usage: 75.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>airport</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>bus_ter</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "      <th>avg_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>YES</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.19200</td>\n",
       "      <td>River</td>\n",
       "      <td>23</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.17280</td>\n",
       "      <td>Lake</td>\n",
       "      <td>42</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.394</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>YES</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.26720</td>\n",
       "      <td>Lake</td>\n",
       "      <td>45</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>NO</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.28960</td>\n",
       "      <td>Lake</td>\n",
       "      <td>55</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  resid_area  air_qual  room_num   age  teachers  poor_prop airport  \\\n",
       "0   24.0       32.31     0.538     6.575  65.2      24.7       4.98     YES   \n",
       "1   21.6       37.07     0.469     6.421  78.9      22.2       9.14      NO   \n",
       "2   34.7       37.07     0.469     7.185  61.1      22.2       4.03      NO   \n",
       "3   33.4       32.18     0.458     6.998  45.8      21.3       2.94     YES   \n",
       "4   36.2       32.18     0.458     7.147  54.2      21.3       5.33      NO   \n",
       "\n",
       "   n_hos_beds  n_hot_rooms waterbody  rainfall bus_ter     parks  Sold  \\\n",
       "0       5.480     11.19200     River        23     YES  0.049347     0   \n",
       "1       7.332     12.17280      Lake        42     YES  0.046146     1   \n",
       "2       7.394     46.19856      None        38     YES  0.045764     0   \n",
       "3       9.268     11.26720      Lake        45     YES  0.047151     0   \n",
       "4       8.824     11.28960      Lake        55     YES  0.039474     0   \n",
       "\n",
       "   avg_dist  \n",
       "0    4.0875  \n",
       "1    4.9675  \n",
       "2    4.9675  \n",
       "3    6.0650  \n",
       "4    6.0625  "
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_dist']=(df.dist1+df.dist2+df.dist3+df.dist4)/4\n",
    "del df['dist1']\n",
    "del df['dist2']\n",
    "del df['dist3']\n",
    "del df['dist4']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_NO</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_None</th>\n",
       "      <th>waterbody_River</th>\n",
       "      <th>bus_ter_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>23</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.1728</td>\n",
       "      <td>42</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  resid_area  air_qual  room_num   age  teachers  poor_prop  \\\n",
       "0   24.0       32.31     0.538     6.575  65.2      24.7       4.98   \n",
       "1   21.6       37.07     0.469     6.421  78.9      22.2       9.14   \n",
       "\n",
       "   n_hos_beds  n_hot_rooms  rainfall     parks  Sold  avg_dist  airport_NO  \\\n",
       "0       5.480      11.1920        23  0.049347     0    4.0875           0   \n",
       "1       7.332      12.1728        42  0.046146     1    4.9675           1   \n",
       "\n",
       "   airport_YES  waterbody_Lake  waterbody_Lake and River  waterbody_None  \\\n",
       "0            1               0                         0               0   \n",
       "1            0               1                         0               0   \n",
       "\n",
       "   waterbody_River  bus_ter_YES  \n",
       "0                1            1  \n",
       "1                0            1  "
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df) #to assign number to string varuable\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['airport_NO']\n",
    "del df['waterbody_None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>Sold</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "      <th>bus_ter_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.484754</td>\n",
       "      <td>-0.429300</td>\n",
       "      <td>0.696304</td>\n",
       "      <td>-0.377999</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>-0.740836</td>\n",
       "      <td>0.108880</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>-0.047200</td>\n",
       "      <td>-0.391574</td>\n",
       "      <td>-0.154698</td>\n",
       "      <td>0.249289</td>\n",
       "      <td>0.182867</td>\n",
       "      <td>0.036233</td>\n",
       "      <td>-0.037497</td>\n",
       "      <td>0.071751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resid_area</th>\n",
       "      <td>-0.484754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.383248</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>0.055845</td>\n",
       "      <td>0.707635</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>-0.708022</td>\n",
       "      <td>-0.115401</td>\n",
       "      <td>-0.026590</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>-0.098976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_qual</th>\n",
       "      <td>-0.429300</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.188933</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.049553</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.091956</td>\n",
       "      <td>0.915544</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.769247</td>\n",
       "      <td>-0.073903</td>\n",
       "      <td>-0.046393</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>-0.037772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_num</th>\n",
       "      <td>0.696304</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>-0.064718</td>\n",
       "      <td>-0.282817</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.205241</td>\n",
       "      <td>0.163774</td>\n",
       "      <td>-0.004195</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.046251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.377999</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261515</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.021012</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>0.074684</td>\n",
       "      <td>0.673850</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>-0.088609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teachers</th>\n",
       "      <td>0.505655</td>\n",
       "      <td>-0.383248</td>\n",
       "      <td>-0.188933</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>-0.261515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.374044</td>\n",
       "      <td>-0.008056</td>\n",
       "      <td>-0.037007</td>\n",
       "      <td>-0.045928</td>\n",
       "      <td>-0.187004</td>\n",
       "      <td>0.042525</td>\n",
       "      <td>0.232452</td>\n",
       "      <td>0.069437</td>\n",
       "      <td>0.048717</td>\n",
       "      <td>-0.046981</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor_prop</th>\n",
       "      <td>-0.740836</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.374044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066008</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>0.552310</td>\n",
       "      <td>-0.082776</td>\n",
       "      <td>-0.496967</td>\n",
       "      <td>-0.095054</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>-0.109004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hos_beds</th>\n",
       "      <td>0.108880</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>-0.049553</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>-0.021012</td>\n",
       "      <td>-0.008056</td>\n",
       "      <td>-0.066008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>0.058596</td>\n",
       "      <td>-0.071272</td>\n",
       "      <td>0.066847</td>\n",
       "      <td>-0.027871</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.059482</td>\n",
       "      <td>-0.074148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <td>0.017007</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>-0.037007</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>-0.090338</td>\n",
       "      <td>-0.020700</td>\n",
       "      <td>-0.055338</td>\n",
       "      <td>0.037925</td>\n",
       "      <td>0.014755</td>\n",
       "      <td>-0.064096</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall</th>\n",
       "      <td>-0.047200</td>\n",
       "      <td>0.055845</td>\n",
       "      <td>0.091956</td>\n",
       "      <td>-0.064718</td>\n",
       "      <td>0.074684</td>\n",
       "      <td>-0.045928</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>0.058596</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078278</td>\n",
       "      <td>-0.040114</td>\n",
       "      <td>-0.037285</td>\n",
       "      <td>-0.013171</td>\n",
       "      <td>-0.016170</td>\n",
       "      <td>0.109234</td>\n",
       "      <td>-0.037016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parks</th>\n",
       "      <td>-0.391574</td>\n",
       "      <td>0.707635</td>\n",
       "      <td>0.915544</td>\n",
       "      <td>-0.282817</td>\n",
       "      <td>0.673850</td>\n",
       "      <td>-0.187004</td>\n",
       "      <td>0.552310</td>\n",
       "      <td>-0.071272</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.078278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>-0.707924</td>\n",
       "      <td>-0.052503</td>\n",
       "      <td>-0.034991</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sold</th>\n",
       "      <td>-0.154698</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.042525</td>\n",
       "      <td>-0.082776</td>\n",
       "      <td>0.066847</td>\n",
       "      <td>-0.090338</td>\n",
       "      <td>-0.040114</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038810</td>\n",
       "      <td>-0.070371</td>\n",
       "      <td>-0.061414</td>\n",
       "      <td>-0.003117</td>\n",
       "      <td>0.072842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_dist</th>\n",
       "      <td>0.249289</td>\n",
       "      <td>-0.708022</td>\n",
       "      <td>-0.769247</td>\n",
       "      <td>0.205241</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>0.232452</td>\n",
       "      <td>-0.496967</td>\n",
       "      <td>-0.027871</td>\n",
       "      <td>-0.020700</td>\n",
       "      <td>-0.037285</td>\n",
       "      <td>-0.707924</td>\n",
       "      <td>-0.038810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021402</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>-0.021320</td>\n",
       "      <td>0.032247</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_YES</th>\n",
       "      <td>0.182867</td>\n",
       "      <td>-0.115401</td>\n",
       "      <td>-0.073903</td>\n",
       "      <td>0.163774</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.069437</td>\n",
       "      <td>-0.095054</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.055338</td>\n",
       "      <td>-0.013171</td>\n",
       "      <td>-0.052503</td>\n",
       "      <td>-0.070371</td>\n",
       "      <td>0.021402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>-0.070341</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <td>0.036233</td>\n",
       "      <td>-0.026590</td>\n",
       "      <td>-0.046393</td>\n",
       "      <td>-0.004195</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.048717</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.037925</td>\n",
       "      <td>-0.016170</td>\n",
       "      <td>-0.034991</td>\n",
       "      <td>-0.061414</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196747</td>\n",
       "      <td>-0.366563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <td>-0.037497</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>-0.046981</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.059482</td>\n",
       "      <td>0.014755</td>\n",
       "      <td>0.109234</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>-0.003117</td>\n",
       "      <td>-0.021320</td>\n",
       "      <td>-0.070341</td>\n",
       "      <td>-0.196747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterbody_River</th>\n",
       "      <td>0.071751</td>\n",
       "      <td>-0.098976</td>\n",
       "      <td>-0.037772</td>\n",
       "      <td>0.046251</td>\n",
       "      <td>-0.088609</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>-0.109004</td>\n",
       "      <td>-0.074148</td>\n",
       "      <td>-0.064096</td>\n",
       "      <td>-0.037016</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>0.072842</td>\n",
       "      <td>0.032247</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>-0.366563</td>\n",
       "      <td>-0.304095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus_ter_YES</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             price  resid_area  air_qual  room_num       age  \\\n",
       "price                     1.000000   -0.484754 -0.429300  0.696304 -0.377999   \n",
       "resid_area               -0.484754    1.000000  0.763651 -0.391676  0.644779   \n",
       "air_qual                 -0.429300    0.763651  1.000000 -0.302188  0.731470   \n",
       "room_num                  0.696304   -0.391676 -0.302188  1.000000 -0.240265   \n",
       "age                      -0.377999    0.644779  0.731470 -0.240265  1.000000   \n",
       "teachers                  0.505655   -0.383248 -0.188933  0.355501 -0.261515   \n",
       "poor_prop                -0.740836    0.603800  0.590879 -0.613808  0.602339   \n",
       "n_hos_beds                0.108880    0.005799 -0.049553  0.032009 -0.021012   \n",
       "n_hot_rooms               0.017007   -0.003761  0.007238  0.014583  0.013918   \n",
       "rainfall                 -0.047200    0.055845  0.091956 -0.064718  0.074684   \n",
       "parks                    -0.391574    0.707635  0.915544 -0.282817  0.673850   \n",
       "Sold                     -0.154698    0.024404 -0.004017  0.027148 -0.016291   \n",
       "avg_dist                  0.249289   -0.708022 -0.769247  0.205241 -0.747906   \n",
       "airport_YES               0.182867   -0.115401 -0.073903  0.163774  0.005101   \n",
       "waterbody_Lake            0.036233   -0.026590 -0.046393 -0.004195  0.003452   \n",
       "waterbody_Lake and River -0.037497    0.051649  0.013849  0.010554 -0.004354   \n",
       "waterbody_River           0.071751   -0.098976 -0.037772  0.046251 -0.088609   \n",
       "bus_ter_YES                    NaN         NaN       NaN       NaN       NaN   \n",
       "\n",
       "                          teachers  poor_prop  n_hos_beds  n_hot_rooms  \\\n",
       "price                     0.505655  -0.740836    0.108880     0.017007   \n",
       "resid_area               -0.383248   0.603800    0.005799    -0.003761   \n",
       "air_qual                 -0.188933   0.590879   -0.049553     0.007238   \n",
       "room_num                  0.355501  -0.613808    0.032009     0.014583   \n",
       "age                      -0.261515   0.602339   -0.021012     0.013918   \n",
       "teachers                  1.000000  -0.374044   -0.008056    -0.037007   \n",
       "poor_prop                -0.374044   1.000000   -0.066008     0.017036   \n",
       "n_hos_beds               -0.008056  -0.066008    1.000000    -0.003130   \n",
       "n_hot_rooms              -0.037007   0.017036   -0.003130     1.000000   \n",
       "rainfall                 -0.045928   0.061444    0.058596     0.014869   \n",
       "parks                    -0.187004   0.552310   -0.071272     0.023757   \n",
       "Sold                      0.042525  -0.082776    0.066847    -0.090338   \n",
       "avg_dist                  0.232452  -0.496967   -0.027871    -0.020700   \n",
       "airport_YES               0.069437  -0.095054   -0.006365    -0.055338   \n",
       "waterbody_Lake            0.048717   0.003197    0.042278     0.037925   \n",
       "waterbody_Lake and River -0.046981   0.020620    0.059482     0.014755   \n",
       "waterbody_River           0.094256  -0.109004   -0.074148    -0.064096   \n",
       "bus_ter_YES                    NaN        NaN         NaN          NaN   \n",
       "\n",
       "                          rainfall     parks      Sold  avg_dist  airport_YES  \\\n",
       "price                    -0.047200 -0.391574 -0.154698  0.249289     0.182867   \n",
       "resid_area                0.055845  0.707635  0.024404 -0.708022    -0.115401   \n",
       "air_qual                  0.091956  0.915544 -0.004017 -0.769247    -0.073903   \n",
       "room_num                 -0.064718 -0.282817  0.027148  0.205241     0.163774   \n",
       "age                       0.074684  0.673850 -0.016291 -0.747906     0.005101   \n",
       "teachers                 -0.045928 -0.187004  0.042525  0.232452     0.069437   \n",
       "poor_prop                 0.061444  0.552310 -0.082776 -0.496967    -0.095054   \n",
       "n_hos_beds                0.058596 -0.071272  0.066847 -0.027871    -0.006365   \n",
       "n_hot_rooms               0.014869  0.023757 -0.090338 -0.020700    -0.055338   \n",
       "rainfall                  1.000000  0.078278 -0.040114 -0.037285    -0.013171   \n",
       "parks                     0.078278  1.000000  0.004808 -0.707924    -0.052503   \n",
       "Sold                     -0.040114  0.004808  1.000000 -0.038810    -0.070371   \n",
       "avg_dist                 -0.037285 -0.707924 -0.038810  1.000000     0.021402   \n",
       "airport_YES              -0.013171 -0.052503 -0.070371  0.021402     1.000000   \n",
       "waterbody_Lake           -0.016170 -0.034991 -0.061414  0.034890     0.035491   \n",
       "waterbody_Lake and River  0.109234  0.013265 -0.003117 -0.021320    -0.070341   \n",
       "waterbody_River          -0.037016 -0.048862  0.072842  0.032247     0.017341   \n",
       "bus_ter_YES                    NaN       NaN       NaN       NaN          NaN   \n",
       "\n",
       "                          waterbody_Lake  waterbody_Lake and River  \\\n",
       "price                           0.036233                 -0.037497   \n",
       "resid_area                     -0.026590                  0.051649   \n",
       "air_qual                       -0.046393                  0.013849   \n",
       "room_num                       -0.004195                  0.010554   \n",
       "age                             0.003452                 -0.004354   \n",
       "teachers                        0.048717                 -0.046981   \n",
       "poor_prop                       0.003197                  0.020620   \n",
       "n_hos_beds                      0.042278                  0.059482   \n",
       "n_hot_rooms                     0.037925                  0.014755   \n",
       "rainfall                       -0.016170                  0.109234   \n",
       "parks                          -0.034991                  0.013265   \n",
       "Sold                           -0.061414                 -0.003117   \n",
       "avg_dist                        0.034890                 -0.021320   \n",
       "airport_YES                     0.035491                 -0.070341   \n",
       "waterbody_Lake                  1.000000                 -0.196747   \n",
       "waterbody_Lake and River       -0.196747                  1.000000   \n",
       "waterbody_River                -0.366563                 -0.304095   \n",
       "bus_ter_YES                          NaN                       NaN   \n",
       "\n",
       "                          waterbody_River  bus_ter_YES  \n",
       "price                            0.071751          NaN  \n",
       "resid_area                      -0.098976          NaN  \n",
       "air_qual                        -0.037772          NaN  \n",
       "room_num                         0.046251          NaN  \n",
       "age                             -0.088609          NaN  \n",
       "teachers                         0.094256          NaN  \n",
       "poor_prop                       -0.109004          NaN  \n",
       "n_hos_beds                      -0.074148          NaN  \n",
       "n_hot_rooms                     -0.064096          NaN  \n",
       "rainfall                        -0.037016          NaN  \n",
       "parks                           -0.048862          NaN  \n",
       "Sold                             0.072842          NaN  \n",
       "avg_dist                         0.032247          NaN  \n",
       "airport_YES                      0.017341          NaN  \n",
       "waterbody_Lake                  -0.366563          NaN  \n",
       "waterbody_Lake and River        -0.304095          NaN  \n",
       "waterbody_River                  1.000000          NaN  \n",
       "bus_ter_YES                           NaN          NaN  "
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>Sold</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "      <th>bus_ter_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.19200</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.17280</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>7.394</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>32.18</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.26720</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>32.18</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.28960</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22.4</td>\n",
       "      <td>41.93</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.348</td>\n",
       "      <td>12.17920</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20.6</td>\n",
       "      <td>41.93</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>6.612</td>\n",
       "      <td>13.16480</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>23.9</td>\n",
       "      <td>41.93</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.478</td>\n",
       "      <td>12.19120</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>22.0</td>\n",
       "      <td>41.93</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>7.940</td>\n",
       "      <td>15.17600</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>19.0</td>\n",
       "      <td>41.93</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>10.280</td>\n",
       "      <td>10.15200</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  resid_area  room_num   age  teachers  poor_prop  n_hos_beds  \\\n",
       "0     24.0       32.31     6.575  65.2      24.7       4.98       5.480   \n",
       "1     21.6       37.07     6.421  78.9      22.2       9.14       7.332   \n",
       "2     34.7       37.07     7.185  61.1      22.2       4.03       7.394   \n",
       "3     33.4       32.18     6.998  45.8      21.3       2.94       9.268   \n",
       "4     36.2       32.18     7.147  54.2      21.3       5.33       8.824   \n",
       "..     ...         ...       ...   ...       ...        ...         ...   \n",
       "501   22.4       41.93     6.593  69.1      19.0       9.67       9.348   \n",
       "502   20.6       41.93     6.120  76.7      19.0       9.08       6.612   \n",
       "503   23.9       41.93     6.976  91.0      19.0       5.64       5.478   \n",
       "504   22.0       41.93     6.794  89.3      19.0       6.48       7.940   \n",
       "505   19.0       41.93     6.030  80.8      19.0       7.88      10.280   \n",
       "\n",
       "     n_hot_rooms  rainfall  Sold  avg_dist  airport_YES  waterbody_Lake  \\\n",
       "0       11.19200        23     0    4.0875            1               0   \n",
       "1       12.17280        42     1    4.9675            0               1   \n",
       "2       46.19856        38     0    4.9675            0               0   \n",
       "3       11.26720        45     0    6.0650            1               1   \n",
       "4       11.28960        55     0    6.0625            0               1   \n",
       "..           ...       ...   ...       ...          ...             ...   \n",
       "501     12.17920        27     1    2.4775            0               0   \n",
       "502     13.16480        20     1    2.2875            1               0   \n",
       "503     12.19120        31     1    2.1675            0               0   \n",
       "504     15.17600        47     1    2.3900            1               0   \n",
       "505     10.15200        45     1    2.5050            1               0   \n",
       "\n",
       "     waterbody_Lake and River  waterbody_River  bus_ter_YES  \n",
       "0                           0                1            1  \n",
       "1                           0                0            1  \n",
       "2                           0                0            1  \n",
       "3                           0                0            1  \n",
       "4                           0                0            1  \n",
       "..                        ...              ...          ...  \n",
       "501                         1                0            1  \n",
       "502                         1                0            1  \n",
       "503                         0                0            1  \n",
       "504                         0                0            1  \n",
       "505                         0                0            1  \n",
       "\n",
       "[506 rows x 16 columns]"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['parks'] #mirip sama air qual\n",
    "del df['air_qual']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "data=df[['price', 'resid_area', 'room_num', 'age', 'teachers', 'poor_prop',\n",
    "       'n_hos_beds', 'n_hot_rooms', 'rainfall', 'avg_dist',\n",
    "       'airport_YES', 'waterbody_Lake', 'waterbody_Lake and River',\n",
    "       'waterbody_River', 'bus_ter_YES']]\n",
    "target=df[['Sold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 15)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_valid, X_train = data[:253], data[253:]\n",
    "#y_valid, y_train = target[:253], target[253:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(data, target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(300, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(300, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "#model = keras.models.Sequential()\n",
    "#model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "#model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "#model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "#model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 300)          4800        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          90300       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 315)          0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            316         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 95,416\n",
      "Trainable params: 95,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04542346, -0.01628368, -0.04060829, ..., -0.05131198,\n",
       "         0.07158837, -0.12780276],\n",
       "       [ 0.00883947, -0.05760682, -0.10883226, ...,  0.01118539,\n",
       "        -0.05126987, -0.07727025],\n",
       "       [-0.11481529, -0.12803586,  0.13175319, ..., -0.07862153,\n",
       "         0.13210885, -0.1360071 ],\n",
       "       ...,\n",
       "       [-0.04451673,  0.08698483, -0.11039238, ...,  0.03328948,\n",
       "        -0.08076344, -0.04119998],\n",
       "       [ 0.10174274,  0.05389705, -0.01844323, ...,  0.01144984,\n",
       "         0.02489084, -0.10387857],\n",
       "       [-0.02934705,  0.06818275,  0.03815411, ..., -0.12172917,\n",
       "        -0.10629527,  0.01542841]], dtype=float32)"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 300)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/500\n",
      "284/284 [==============================] - 1s 3ms/sample - loss: 5.6493 - accuracy: 0.5176 - val_loss: 4.4186 - val_accuracy: 0.5474\n",
      "Epoch 2/500\n",
      "284/284 [==============================] - 0s 230us/sample - loss: 4.0856 - accuracy: 0.4965 - val_loss: 2.9369 - val_accuracy: 0.5158\n",
      "Epoch 3/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 3.1722 - accuracy: 0.5176 - val_loss: 2.8516 - val_accuracy: 0.5368\n",
      "Epoch 4/500\n",
      "284/284 [==============================] - 0s 394us/sample - loss: 2.4225 - accuracy: 0.5141 - val_loss: 2.0831 - val_accuracy: 0.4316\n",
      "Epoch 5/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 1.6955 - accuracy: 0.4930 - val_loss: 1.5636 - val_accuracy: 0.4526\n",
      "Epoch 6/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 1.5871 - accuracy: 0.4930 - val_loss: 2.8216 - val_accuracy: 0.4211\n",
      "Epoch 7/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 1.8597 - accuracy: 0.5035 - val_loss: 1.8746 - val_accuracy: 0.4632\n",
      "Epoch 8/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.9817 - accuracy: 0.4894 - val_loss: 1.0421 - val_accuracy: 0.4632\n",
      "Epoch 9/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.7911 - accuracy: 0.5035 - val_loss: 0.8372 - val_accuracy: 0.5053\n",
      "Epoch 10/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.7656 - accuracy: 0.5176 - val_loss: 0.8038 - val_accuracy: 0.5053\n",
      "Epoch 11/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.7510 - accuracy: 0.5141 - val_loss: 0.7836 - val_accuracy: 0.5158\n",
      "Epoch 12/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.7012 - accuracy: 0.5317 - val_loss: 0.7479 - val_accuracy: 0.4947\n",
      "Epoch 13/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.6787 - accuracy: 0.5634 - val_loss: 0.7405 - val_accuracy: 0.4947\n",
      "Epoch 14/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.6717 - accuracy: 0.5599 - val_loss: 0.7347 - val_accuracy: 0.4947\n",
      "Epoch 15/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.6646 - accuracy: 0.5669 - val_loss: 0.7291 - val_accuracy: 0.5158\n",
      "Epoch 16/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.6584 - accuracy: 0.5739 - val_loss: 0.7242 - val_accuracy: 0.5263\n",
      "Epoch 17/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.6523 - accuracy: 0.5915 - val_loss: 0.7202 - val_accuracy: 0.5263\n",
      "Epoch 18/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.6470 - accuracy: 0.5880 - val_loss: 0.7168 - val_accuracy: 0.5263\n",
      "Epoch 19/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.6414 - accuracy: 0.6021 - val_loss: 0.7140 - val_accuracy: 0.5158\n",
      "Epoch 20/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.6360 - accuracy: 0.6268 - val_loss: 0.7115 - val_accuracy: 0.5053\n",
      "Epoch 21/500\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.46 - 0s 187us/sample - loss: 0.6311 - accuracy: 0.6232 - val_loss: 0.7086 - val_accuracy: 0.5158\n",
      "Epoch 22/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.6266 - accuracy: 0.6514 - val_loss: 0.7061 - val_accuracy: 0.5368\n",
      "Epoch 23/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.6218 - accuracy: 0.6655 - val_loss: 0.7039 - val_accuracy: 0.5368\n",
      "Epoch 24/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.6176 - accuracy: 0.6655 - val_loss: 0.7018 - val_accuracy: 0.5368\n",
      "Epoch 25/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.6133 - accuracy: 0.6620 - val_loss: 0.6997 - val_accuracy: 0.5368\n",
      "Epoch 26/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.6093 - accuracy: 0.6620 - val_loss: 0.6983 - val_accuracy: 0.5368\n",
      "Epoch 27/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.6050 - accuracy: 0.6725 - val_loss: 0.6961 - val_accuracy: 0.5368\n",
      "Epoch 28/500\n",
      "284/284 [==============================] - 0s 229us/sample - loss: 0.6015 - accuracy: 0.6831 - val_loss: 0.6941 - val_accuracy: 0.5368\n",
      "Epoch 29/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.5976 - accuracy: 0.6831 - val_loss: 0.6929 - val_accuracy: 0.5263\n",
      "Epoch 30/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.5937 - accuracy: 0.6866 - val_loss: 0.6912 - val_accuracy: 0.5368\n",
      "Epoch 31/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.5910 - accuracy: 0.6866 - val_loss: 0.6889 - val_accuracy: 0.5579\n",
      "Epoch 32/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.5871 - accuracy: 0.6866 - val_loss: 0.6881 - val_accuracy: 0.5474\n",
      "Epoch 33/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.5836 - accuracy: 0.6937 - val_loss: 0.6867 - val_accuracy: 0.5579\n",
      "Epoch 34/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.5800 - accuracy: 0.6972 - val_loss: 0.6855 - val_accuracy: 0.5579\n",
      "Epoch 35/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.5773 - accuracy: 0.7077 - val_loss: 0.6840 - val_accuracy: 0.5684\n",
      "Epoch 36/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.5739 - accuracy: 0.7148 - val_loss: 0.6834 - val_accuracy: 0.5684\n",
      "Epoch 37/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.5707 - accuracy: 0.7077 - val_loss: 0.6823 - val_accuracy: 0.5684\n",
      "Epoch 38/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.5674 - accuracy: 0.7113 - val_loss: 0.6812 - val_accuracy: 0.5684\n",
      "Epoch 39/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.5647 - accuracy: 0.7148 - val_loss: 0.6796 - val_accuracy: 0.5684\n",
      "Epoch 40/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.5617 - accuracy: 0.7113 - val_loss: 0.6782 - val_accuracy: 0.5684\n",
      "Epoch 41/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.5592 - accuracy: 0.7183 - val_loss: 0.6775 - val_accuracy: 0.5684\n",
      "Epoch 42/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.5563 - accuracy: 0.7218 - val_loss: 0.6771 - val_accuracy: 0.5684\n",
      "Epoch 43/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.5537 - accuracy: 0.7148 - val_loss: 0.6758 - val_accuracy: 0.5684\n",
      "Epoch 44/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.5508 - accuracy: 0.7183 - val_loss: 0.6746 - val_accuracy: 0.5684\n",
      "Epoch 45/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.5480 - accuracy: 0.7289 - val_loss: 0.6743 - val_accuracy: 0.5789\n",
      "Epoch 46/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.5468 - accuracy: 0.7218 - val_loss: 0.6742 - val_accuracy: 0.5789\n",
      "Epoch 47/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.5436 - accuracy: 0.7359 - val_loss: 0.6729 - val_accuracy: 0.5789\n",
      "Epoch 48/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.5409 - accuracy: 0.7394 - val_loss: 0.6718 - val_accuracy: 0.5789\n",
      "Epoch 49/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.5386 - accuracy: 0.7394 - val_loss: 0.6707 - val_accuracy: 0.5684\n",
      "Epoch 50/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.5362 - accuracy: 0.7465 - val_loss: 0.6703 - val_accuracy: 0.5579\n",
      "Epoch 51/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.5334 - accuracy: 0.7500 - val_loss: 0.6695 - val_accuracy: 0.5579\n",
      "Epoch 52/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.5315 - accuracy: 0.7430 - val_loss: 0.6687 - val_accuracy: 0.5579\n",
      "Epoch 53/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.5289 - accuracy: 0.7535 - val_loss: 0.6685 - val_accuracy: 0.5579\n",
      "Epoch 54/500\n",
      "284/284 [==============================] - 0s 215us/sample - loss: 0.5268 - accuracy: 0.7465 - val_loss: 0.6686 - val_accuracy: 0.5579\n",
      "Epoch 55/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.5250 - accuracy: 0.7430 - val_loss: 0.6675 - val_accuracy: 0.5579\n",
      "Epoch 56/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.5224 - accuracy: 0.7500 - val_loss: 0.6666 - val_accuracy: 0.5684\n",
      "Epoch 57/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.5205 - accuracy: 0.7500 - val_loss: 0.6664 - val_accuracy: 0.5579\n",
      "Epoch 58/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.5181 - accuracy: 0.7535 - val_loss: 0.6662 - val_accuracy: 0.5579\n",
      "Epoch 59/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.5160 - accuracy: 0.7535 - val_loss: 0.6660 - val_accuracy: 0.5789\n",
      "Epoch 60/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.5142 - accuracy: 0.7606 - val_loss: 0.6659 - val_accuracy: 0.5895\n",
      "Epoch 61/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.5118 - accuracy: 0.7606 - val_loss: 0.6657 - val_accuracy: 0.5895\n",
      "Epoch 62/500\n",
      "284/284 [==============================] - 0s 109us/sample - loss: 0.5098 - accuracy: 0.7641 - val_loss: 0.6653 - val_accuracy: 0.5789\n",
      "Epoch 63/500\n",
      "284/284 [==============================] - 0s 252us/sample - loss: 0.5083 - accuracy: 0.7570 - val_loss: 0.6657 - val_accuracy: 0.5789\n",
      "Epoch 64/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.5059 - accuracy: 0.7641 - val_loss: 0.6655 - val_accuracy: 0.6000\n",
      "Epoch 65/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.5042 - accuracy: 0.7641 - val_loss: 0.6655 - val_accuracy: 0.6000\n",
      "Epoch 66/500\n",
      "284/284 [==============================] - 0s 232us/sample - loss: 0.5024 - accuracy: 0.7676 - val_loss: 0.6662 - val_accuracy: 0.5789\n",
      "Epoch 67/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.5007 - accuracy: 0.7641 - val_loss: 0.6657 - val_accuracy: 0.5895\n",
      "Epoch 68/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.4990 - accuracy: 0.7711 - val_loss: 0.6656 - val_accuracy: 0.5895\n",
      "Epoch 69/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.4972 - accuracy: 0.7746 - val_loss: 0.6652 - val_accuracy: 0.5895\n",
      "Epoch 70/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4949 - accuracy: 0.7746 - val_loss: 0.6654 - val_accuracy: 0.5895\n",
      "Epoch 71/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4933 - accuracy: 0.7641 - val_loss: 0.6648 - val_accuracy: 0.6000\n",
      "Epoch 72/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.4913 - accuracy: 0.7676 - val_loss: 0.6642 - val_accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4896 - accuracy: 0.7746 - val_loss: 0.6638 - val_accuracy: 0.6000\n",
      "Epoch 74/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.4881 - accuracy: 0.7711 - val_loss: 0.6633 - val_accuracy: 0.6000\n",
      "Epoch 75/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.4870 - accuracy: 0.7887 - val_loss: 0.6619 - val_accuracy: 0.6105\n",
      "Epoch 76/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.4848 - accuracy: 0.7746 - val_loss: 0.6622 - val_accuracy: 0.6105\n",
      "Epoch 77/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.4832 - accuracy: 0.7817 - val_loss: 0.6619 - val_accuracy: 0.6105\n",
      "Epoch 78/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.4814 - accuracy: 0.7817 - val_loss: 0.6629 - val_accuracy: 0.6105\n",
      "Epoch 79/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4798 - accuracy: 0.7852 - val_loss: 0.6637 - val_accuracy: 0.6105\n",
      "Epoch 80/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.4783 - accuracy: 0.7852 - val_loss: 0.6638 - val_accuracy: 0.6105\n",
      "Epoch 81/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.4769 - accuracy: 0.7746 - val_loss: 0.6650 - val_accuracy: 0.6105\n",
      "Epoch 82/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.4752 - accuracy: 0.7852 - val_loss: 0.6647 - val_accuracy: 0.6211\n",
      "Epoch 83/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.4738 - accuracy: 0.7887 - val_loss: 0.6656 - val_accuracy: 0.6211\n",
      "Epoch 84/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.4724 - accuracy: 0.7887 - val_loss: 0.6677 - val_accuracy: 0.6211\n",
      "Epoch 85/500\n",
      "284/284 [==============================] - 0s 454us/sample - loss: 0.4703 - accuracy: 0.7923 - val_loss: 0.6699 - val_accuracy: 0.6211\n",
      "Epoch 86/500\n",
      "284/284 [==============================] - 0s 229us/sample - loss: 0.4691 - accuracy: 0.7887 - val_loss: 0.6727 - val_accuracy: 0.6105\n",
      "Epoch 87/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.4671 - accuracy: 0.7958 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 88/500\n",
      "284/284 [==============================] - 0s 260us/sample - loss: 0.4661 - accuracy: 0.7958 - val_loss: 0.6785 - val_accuracy: 0.6000\n",
      "Epoch 89/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4644 - accuracy: 0.7958 - val_loss: 0.6813 - val_accuracy: 0.6211\n",
      "Epoch 90/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4630 - accuracy: 0.7958 - val_loss: 0.6897 - val_accuracy: 0.6105\n",
      "Epoch 91/500\n",
      "284/284 [==============================] - 0s 199us/sample - loss: 0.4613 - accuracy: 0.8063 - val_loss: 0.7894 - val_accuracy: 0.6105\n",
      "Epoch 92/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4603 - accuracy: 0.8063 - val_loss: 0.7891 - val_accuracy: 0.6105\n",
      "Epoch 93/500\n",
      "284/284 [==============================] - 0s 239us/sample - loss: 0.4583 - accuracy: 0.7993 - val_loss: 0.7885 - val_accuracy: 0.6211\n",
      "Epoch 94/500\n",
      "284/284 [==============================] - 0s 239us/sample - loss: 0.4571 - accuracy: 0.7993 - val_loss: 0.7886 - val_accuracy: 0.6105\n",
      "Epoch 95/500\n",
      "284/284 [==============================] - 0s 264us/sample - loss: 0.4560 - accuracy: 0.8028 - val_loss: 0.7877 - val_accuracy: 0.6211\n",
      "Epoch 96/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4542 - accuracy: 0.8063 - val_loss: 0.7881 - val_accuracy: 0.6105\n",
      "Epoch 97/500\n",
      "284/284 [==============================] - 0s 243us/sample - loss: 0.4531 - accuracy: 0.8063 - val_loss: 0.7880 - val_accuracy: 0.6105\n",
      "Epoch 98/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.4518 - accuracy: 0.8099 - val_loss: 0.7872 - val_accuracy: 0.6211\n",
      "Epoch 99/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4501 - accuracy: 0.8028 - val_loss: 0.7871 - val_accuracy: 0.6211\n",
      "Epoch 100/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.4489 - accuracy: 0.8028 - val_loss: 0.7873 - val_accuracy: 0.6211\n",
      "Epoch 101/500\n",
      "284/284 [==============================] - 0s 225us/sample - loss: 0.4476 - accuracy: 0.8099 - val_loss: 0.7875 - val_accuracy: 0.6000\n",
      "Epoch 102/500\n",
      "284/284 [==============================] - 0s 271us/sample - loss: 0.4460 - accuracy: 0.8169 - val_loss: 0.7867 - val_accuracy: 0.6105\n",
      "Epoch 103/500\n",
      "284/284 [==============================] - 0s 246us/sample - loss: 0.4446 - accuracy: 0.8099 - val_loss: 0.7864 - val_accuracy: 0.6105\n",
      "Epoch 104/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4434 - accuracy: 0.8134 - val_loss: 0.7864 - val_accuracy: 0.6105\n",
      "Epoch 105/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.4420 - accuracy: 0.8099 - val_loss: 0.7855 - val_accuracy: 0.6000\n",
      "Epoch 106/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4404 - accuracy: 0.8099 - val_loss: 0.7858 - val_accuracy: 0.6000\n",
      "Epoch 107/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4389 - accuracy: 0.8169 - val_loss: 0.7855 - val_accuracy: 0.6000\n",
      "Epoch 108/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.4382 - accuracy: 0.8134 - val_loss: 0.7845 - val_accuracy: 0.6000\n",
      "Epoch 109/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4367 - accuracy: 0.8239 - val_loss: 0.7844 - val_accuracy: 0.6000\n",
      "Epoch 110/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4354 - accuracy: 0.8239 - val_loss: 0.7844 - val_accuracy: 0.6000\n",
      "Epoch 111/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.4343 - accuracy: 0.8204 - val_loss: 0.7844 - val_accuracy: 0.6000\n",
      "Epoch 112/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.4327 - accuracy: 0.8239 - val_loss: 0.7843 - val_accuracy: 0.6105\n",
      "Epoch 113/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4318 - accuracy: 0.8275 - val_loss: 0.7835 - val_accuracy: 0.6105\n",
      "Epoch 114/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4304 - accuracy: 0.8204 - val_loss: 0.7827 - val_accuracy: 0.6211\n",
      "Epoch 115/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.4293 - accuracy: 0.8275 - val_loss: 0.7817 - val_accuracy: 0.6211\n",
      "Epoch 116/500\n",
      "284/284 [==============================] - 0s 222us/sample - loss: 0.4277 - accuracy: 0.8239 - val_loss: 0.7823 - val_accuracy: 0.6211\n",
      "Epoch 117/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.4268 - accuracy: 0.8275 - val_loss: 0.7830 - val_accuracy: 0.6105\n",
      "Epoch 118/500\n",
      "284/284 [==============================] - 0s 278us/sample - loss: 0.4253 - accuracy: 0.8239 - val_loss: 0.7829 - val_accuracy: 0.6211\n",
      "Epoch 119/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.4240 - accuracy: 0.8239 - val_loss: 0.7824 - val_accuracy: 0.6211\n",
      "Epoch 120/500\n",
      "284/284 [==============================] - 0s 282us/sample - loss: 0.4231 - accuracy: 0.8275 - val_loss: 0.7826 - val_accuracy: 0.6211\n",
      "Epoch 121/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.4221 - accuracy: 0.8310 - val_loss: 0.7816 - val_accuracy: 0.6211\n",
      "Epoch 122/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.4205 - accuracy: 0.8275 - val_loss: 0.7825 - val_accuracy: 0.6211\n",
      "Epoch 123/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4198 - accuracy: 0.8310 - val_loss: 0.7819 - val_accuracy: 0.6211\n",
      "Epoch 124/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4186 - accuracy: 0.8275 - val_loss: 0.7821 - val_accuracy: 0.6316\n",
      "Epoch 125/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.4178 - accuracy: 0.8345 - val_loss: 0.7817 - val_accuracy: 0.6316\n",
      "Epoch 126/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.4158 - accuracy: 0.8310 - val_loss: 0.7811 - val_accuracy: 0.6421\n",
      "Epoch 127/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4152 - accuracy: 0.8310 - val_loss: 0.7805 - val_accuracy: 0.6421\n",
      "Epoch 128/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4138 - accuracy: 0.8310 - val_loss: 0.7798 - val_accuracy: 0.6421\n",
      "Epoch 129/500\n",
      "284/284 [==============================] - 0s 171us/sample - loss: 0.4131 - accuracy: 0.8310 - val_loss: 0.7794 - val_accuracy: 0.6526\n",
      "Epoch 130/500\n",
      "284/284 [==============================] - 0s 178us/sample - loss: 0.4114 - accuracy: 0.8345 - val_loss: 0.7792 - val_accuracy: 0.6421\n",
      "Epoch 131/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.4103 - accuracy: 0.8345 - val_loss: 0.7801 - val_accuracy: 0.6316\n",
      "Epoch 132/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4097 - accuracy: 0.8345 - val_loss: 0.7808 - val_accuracy: 0.6316\n",
      "Epoch 133/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.4082 - accuracy: 0.8345 - val_loss: 0.7810 - val_accuracy: 0.6316\n",
      "Epoch 134/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.4072 - accuracy: 0.8345 - val_loss: 0.7819 - val_accuracy: 0.6211\n",
      "Epoch 135/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.4061 - accuracy: 0.8345 - val_loss: 0.7823 - val_accuracy: 0.6211\n",
      "Epoch 136/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.4052 - accuracy: 0.8345 - val_loss: 0.7818 - val_accuracy: 0.6316\n",
      "Epoch 137/500\n",
      "284/284 [==============================] - 0s 222us/sample - loss: 0.4043 - accuracy: 0.8345 - val_loss: 0.7814 - val_accuracy: 0.6316\n",
      "Epoch 138/500\n",
      "284/284 [==============================] - 0s 229us/sample - loss: 0.4028 - accuracy: 0.8380 - val_loss: 0.7813 - val_accuracy: 0.6316\n",
      "Epoch 139/500\n",
      "284/284 [==============================] - 0s 355us/sample - loss: 0.4020 - accuracy: 0.8380 - val_loss: 0.7817 - val_accuracy: 0.6316\n",
      "Epoch 140/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.4007 - accuracy: 0.8345 - val_loss: 0.7823 - val_accuracy: 0.6316\n",
      "Epoch 141/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.4000 - accuracy: 0.8345 - val_loss: 0.7822 - val_accuracy: 0.6316\n",
      "Epoch 142/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3989 - accuracy: 0.8380 - val_loss: 0.7831 - val_accuracy: 0.6316\n",
      "Epoch 143/500\n",
      "284/284 [==============================] - 0s 267us/sample - loss: 0.3976 - accuracy: 0.8380 - val_loss: 0.7841 - val_accuracy: 0.6316\n",
      "Epoch 144/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.3969 - accuracy: 0.8380 - val_loss: 0.7832 - val_accuracy: 0.6316\n",
      "Epoch 145/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3959 - accuracy: 0.8380 - val_loss: 0.7826 - val_accuracy: 0.6211\n",
      "Epoch 146/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3950 - accuracy: 0.8415 - val_loss: 0.7831 - val_accuracy: 0.6211\n",
      "Epoch 147/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3939 - accuracy: 0.8380 - val_loss: 0.7823 - val_accuracy: 0.6211\n",
      "Epoch 148/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.3927 - accuracy: 0.8415 - val_loss: 0.7832 - val_accuracy: 0.6211\n",
      "Epoch 149/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3916 - accuracy: 0.8415 - val_loss: 0.7826 - val_accuracy: 0.6211\n",
      "Epoch 150/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3912 - accuracy: 0.8451 - val_loss: 0.7836 - val_accuracy: 0.6211\n",
      "Epoch 151/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3899 - accuracy: 0.8415 - val_loss: 0.7838 - val_accuracy: 0.6211\n",
      "Epoch 152/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3893 - accuracy: 0.8415 - val_loss: 0.7849 - val_accuracy: 0.6316\n",
      "Epoch 153/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3885 - accuracy: 0.8415 - val_loss: 0.7844 - val_accuracy: 0.6211\n",
      "Epoch 154/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3872 - accuracy: 0.8380 - val_loss: 0.7846 - val_accuracy: 0.6211\n",
      "Epoch 155/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3868 - accuracy: 0.8486 - val_loss: 0.7860 - val_accuracy: 0.6211\n",
      "Epoch 156/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3856 - accuracy: 0.8451 - val_loss: 0.7862 - val_accuracy: 0.6316\n",
      "Epoch 157/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3844 - accuracy: 0.8451 - val_loss: 0.7869 - val_accuracy: 0.6316\n",
      "Epoch 158/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3836 - accuracy: 0.8415 - val_loss: 0.7874 - val_accuracy: 0.6316\n",
      "Epoch 159/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3827 - accuracy: 0.8415 - val_loss: 0.7873 - val_accuracy: 0.6316\n",
      "Epoch 160/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.3824 - accuracy: 0.8451 - val_loss: 0.7870 - val_accuracy: 0.6316\n",
      "Epoch 161/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3808 - accuracy: 0.8486 - val_loss: 0.7880 - val_accuracy: 0.6316\n",
      "Epoch 162/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3800 - accuracy: 0.8486 - val_loss: 0.7885 - val_accuracy: 0.6316\n",
      "Epoch 163/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.3791 - accuracy: 0.8415 - val_loss: 0.7885 - val_accuracy: 0.6316\n",
      "Epoch 164/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3787 - accuracy: 0.8415 - val_loss: 0.7892 - val_accuracy: 0.6316\n",
      "Epoch 165/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3773 - accuracy: 0.8486 - val_loss: 0.7895 - val_accuracy: 0.6316\n",
      "Epoch 166/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3763 - accuracy: 0.8486 - val_loss: 0.7893 - val_accuracy: 0.6316\n",
      "Epoch 167/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3755 - accuracy: 0.8486 - val_loss: 0.7898 - val_accuracy: 0.6316\n",
      "Epoch 168/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3749 - accuracy: 0.8486 - val_loss: 0.7895 - val_accuracy: 0.6211\n",
      "Epoch 169/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3738 - accuracy: 0.8486 - val_loss: 0.7899 - val_accuracy: 0.6211\n",
      "Epoch 170/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3728 - accuracy: 0.8451 - val_loss: 0.7899 - val_accuracy: 0.6211\n",
      "Epoch 171/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3725 - accuracy: 0.8486 - val_loss: 0.7894 - val_accuracy: 0.6211\n",
      "Epoch 172/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3715 - accuracy: 0.8521 - val_loss: 0.7911 - val_accuracy: 0.6316\n",
      "Epoch 173/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3705 - accuracy: 0.8556 - val_loss: 0.7916 - val_accuracy: 0.6211\n",
      "Epoch 174/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3696 - accuracy: 0.8521 - val_loss: 0.7925 - val_accuracy: 0.6316\n",
      "Epoch 175/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3688 - accuracy: 0.8521 - val_loss: 0.7925 - val_accuracy: 0.6316\n",
      "Epoch 176/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3681 - accuracy: 0.8486 - val_loss: 0.7917 - val_accuracy: 0.6211\n",
      "Epoch 177/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.3672 - accuracy: 0.8556 - val_loss: 0.7945 - val_accuracy: 0.6316\n",
      "Epoch 178/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3662 - accuracy: 0.8486 - val_loss: 0.7956 - val_accuracy: 0.6105\n",
      "Epoch 179/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.3652 - accuracy: 0.8486 - val_loss: 0.7958 - val_accuracy: 0.6105\n",
      "Epoch 180/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3645 - accuracy: 0.8486 - val_loss: 0.7951 - val_accuracy: 0.6211\n",
      "Epoch 181/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3638 - accuracy: 0.8521 - val_loss: 0.7950 - val_accuracy: 0.6211\n",
      "Epoch 182/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.3638 - accuracy: 0.8486 - val_loss: 0.7942 - val_accuracy: 0.6105\n",
      "Epoch 183/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3620 - accuracy: 0.8521 - val_loss: 0.7951 - val_accuracy: 0.6211\n",
      "Epoch 184/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3615 - accuracy: 0.8486 - val_loss: 0.7948 - val_accuracy: 0.6211\n",
      "Epoch 185/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3604 - accuracy: 0.8486 - val_loss: 0.7956 - val_accuracy: 0.6211\n",
      "Epoch 186/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3598 - accuracy: 0.8486 - val_loss: 0.7965 - val_accuracy: 0.6211\n",
      "Epoch 187/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3589 - accuracy: 0.8486 - val_loss: 0.7968 - val_accuracy: 0.6211\n",
      "Epoch 188/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3581 - accuracy: 0.8451 - val_loss: 0.7967 - val_accuracy: 0.6211\n",
      "Epoch 189/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3576 - accuracy: 0.8486 - val_loss: 0.7977 - val_accuracy: 0.6211\n",
      "Epoch 190/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3566 - accuracy: 0.8521 - val_loss: 0.7984 - val_accuracy: 0.6211\n",
      "Epoch 191/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3558 - accuracy: 0.8486 - val_loss: 0.7982 - val_accuracy: 0.6211\n",
      "Epoch 192/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3553 - accuracy: 0.8451 - val_loss: 0.7975 - val_accuracy: 0.6211\n",
      "Epoch 193/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3545 - accuracy: 0.8451 - val_loss: 0.7980 - val_accuracy: 0.6211\n",
      "Epoch 194/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3538 - accuracy: 0.8451 - val_loss: 0.7984 - val_accuracy: 0.6211\n",
      "Epoch 195/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.3530 - accuracy: 0.8486 - val_loss: 0.7976 - val_accuracy: 0.6211\n",
      "Epoch 196/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3525 - accuracy: 0.8451 - val_loss: 0.7989 - val_accuracy: 0.6211\n",
      "Epoch 197/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3516 - accuracy: 0.8486 - val_loss: 0.7988 - val_accuracy: 0.6211\n",
      "Epoch 198/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3506 - accuracy: 0.8486 - val_loss: 0.7990 - val_accuracy: 0.6211\n",
      "Epoch 199/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.3502 - accuracy: 0.8486 - val_loss: 0.7989 - val_accuracy: 0.6211\n",
      "Epoch 200/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3492 - accuracy: 0.8486 - val_loss: 0.7990 - val_accuracy: 0.6211\n",
      "Epoch 201/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.3488 - accuracy: 0.8486 - val_loss: 0.7998 - val_accuracy: 0.6211\n",
      "Epoch 202/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3481 - accuracy: 0.8451 - val_loss: 0.8002 - val_accuracy: 0.6211\n",
      "Epoch 203/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3477 - accuracy: 0.8486 - val_loss: 0.7996 - val_accuracy: 0.6211\n",
      "Epoch 204/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3465 - accuracy: 0.8486 - val_loss: 0.8009 - val_accuracy: 0.6211\n",
      "Epoch 205/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3457 - accuracy: 0.8521 - val_loss: 0.8004 - val_accuracy: 0.6211\n",
      "Epoch 206/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3452 - accuracy: 0.8486 - val_loss: 0.7995 - val_accuracy: 0.6211\n",
      "Epoch 207/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.3444 - accuracy: 0.8556 - val_loss: 0.7997 - val_accuracy: 0.6211\n",
      "Epoch 208/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.3440 - accuracy: 0.8486 - val_loss: 0.8023 - val_accuracy: 0.6211\n",
      "Epoch 209/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3431 - accuracy: 0.8486 - val_loss: 0.8013 - val_accuracy: 0.6211\n",
      "Epoch 210/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3426 - accuracy: 0.8556 - val_loss: 0.8020 - val_accuracy: 0.6211\n",
      "Epoch 211/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3419 - accuracy: 0.8486 - val_loss: 0.8010 - val_accuracy: 0.6211\n",
      "Epoch 212/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3413 - accuracy: 0.8556 - val_loss: 0.8035 - val_accuracy: 0.6211\n",
      "Epoch 213/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.3406 - accuracy: 0.8521 - val_loss: 0.8023 - val_accuracy: 0.6211\n",
      "Epoch 214/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3399 - accuracy: 0.8486 - val_loss: 0.8017 - val_accuracy: 0.6211\n",
      "Epoch 215/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3391 - accuracy: 0.8521 - val_loss: 0.8024 - val_accuracy: 0.6211\n",
      "Epoch 216/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3388 - accuracy: 0.8486 - val_loss: 0.8033 - val_accuracy: 0.6211\n",
      "Epoch 217/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3377 - accuracy: 0.8521 - val_loss: 0.8040 - val_accuracy: 0.6211\n",
      "Epoch 218/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3370 - accuracy: 0.8521 - val_loss: 0.8031 - val_accuracy: 0.6211\n",
      "Epoch 219/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3363 - accuracy: 0.8521 - val_loss: 0.8030 - val_accuracy: 0.6211\n",
      "Epoch 220/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3356 - accuracy: 0.8521 - val_loss: 0.8040 - val_accuracy: 0.6211\n",
      "Epoch 221/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.3354 - accuracy: 0.8521 - val_loss: 0.8024 - val_accuracy: 0.6105\n",
      "Epoch 222/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.3347 - accuracy: 0.8521 - val_loss: 0.8018 - val_accuracy: 0.6105\n",
      "Epoch 223/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3340 - accuracy: 0.8521 - val_loss: 0.8044 - val_accuracy: 0.6316\n",
      "Epoch 224/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.3333 - accuracy: 0.8521 - val_loss: 0.8044 - val_accuracy: 0.6316\n",
      "Epoch 225/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3326 - accuracy: 0.8521 - val_loss: 0.8059 - val_accuracy: 0.6316\n",
      "Epoch 226/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.3318 - accuracy: 0.8521 - val_loss: 0.8048 - val_accuracy: 0.6316\n",
      "Epoch 227/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3309 - accuracy: 0.8556 - val_loss: 0.8041 - val_accuracy: 0.6211\n",
      "Epoch 228/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.3308 - accuracy: 0.8556 - val_loss: 0.8030 - val_accuracy: 0.6211\n",
      "Epoch 229/500\n",
      "284/284 [==============================] - 0s 429us/sample - loss: 0.3299 - accuracy: 0.8556 - val_loss: 0.8041 - val_accuracy: 0.6211\n",
      "Epoch 230/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3294 - accuracy: 0.8556 - val_loss: 0.8059 - val_accuracy: 0.6211\n",
      "Epoch 231/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3289 - accuracy: 0.8556 - val_loss: 0.8054 - val_accuracy: 0.6211\n",
      "Epoch 232/500\n",
      "284/284 [==============================] - 0s 144us/sample - loss: 0.3280 - accuracy: 0.8521 - val_loss: 0.8062 - val_accuracy: 0.6211\n",
      "Epoch 233/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3281 - accuracy: 0.8556 - val_loss: 0.8072 - val_accuracy: 0.6211\n",
      "Epoch 234/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3271 - accuracy: 0.8556 - val_loss: 0.8064 - val_accuracy: 0.6211\n",
      "Epoch 235/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3265 - accuracy: 0.8556 - val_loss: 0.8105 - val_accuracy: 0.6211\n",
      "Epoch 236/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.3256 - accuracy: 0.8521 - val_loss: 0.8092 - val_accuracy: 0.6211\n",
      "Epoch 237/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3254 - accuracy: 0.8592 - val_loss: 0.8109 - val_accuracy: 0.6211\n",
      "Epoch 238/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3248 - accuracy: 0.8556 - val_loss: 0.8114 - val_accuracy: 0.6211\n",
      "Epoch 239/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3237 - accuracy: 0.8592 - val_loss: 0.8101 - val_accuracy: 0.6211\n",
      "Epoch 240/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3234 - accuracy: 0.8556 - val_loss: 0.8121 - val_accuracy: 0.6211\n",
      "Epoch 241/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.3229 - accuracy: 0.8556 - val_loss: 0.8131 - val_accuracy: 0.6211\n",
      "Epoch 242/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.3222 - accuracy: 0.8556 - val_loss: 0.8140 - val_accuracy: 0.6211\n",
      "Epoch 243/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3213 - accuracy: 0.8592 - val_loss: 0.8131 - val_accuracy: 0.6211\n",
      "Epoch 244/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3208 - accuracy: 0.8556 - val_loss: 0.8157 - val_accuracy: 0.6211\n",
      "Epoch 245/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3208 - accuracy: 0.8592 - val_loss: 0.8147 - val_accuracy: 0.6211\n",
      "Epoch 246/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.3199 - accuracy: 0.8627 - val_loss: 0.8128 - val_accuracy: 0.6211\n",
      "Epoch 247/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3189 - accuracy: 0.8592 - val_loss: 0.8134 - val_accuracy: 0.6211\n",
      "Epoch 248/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3187 - accuracy: 0.8556 - val_loss: 0.8143 - val_accuracy: 0.6316\n",
      "Epoch 249/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.3178 - accuracy: 0.8592 - val_loss: 0.8159 - val_accuracy: 0.6316\n",
      "Epoch 250/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3173 - accuracy: 0.8592 - val_loss: 0.8167 - val_accuracy: 0.6316\n",
      "Epoch 251/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3177 - accuracy: 0.8592 - val_loss: 0.8177 - val_accuracy: 0.6316\n",
      "Epoch 252/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3163 - accuracy: 0.8592 - val_loss: 0.8183 - val_accuracy: 0.6316\n",
      "Epoch 253/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3158 - accuracy: 0.8592 - val_loss: 0.8170 - val_accuracy: 0.6316\n",
      "Epoch 254/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3152 - accuracy: 0.8627 - val_loss: 0.8190 - val_accuracy: 0.6316\n",
      "Epoch 255/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.3145 - accuracy: 0.8592 - val_loss: 0.8199 - val_accuracy: 0.6316\n",
      "Epoch 256/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3140 - accuracy: 0.8592 - val_loss: 0.8212 - val_accuracy: 0.6316\n",
      "Epoch 257/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3132 - accuracy: 0.8592 - val_loss: 0.8214 - val_accuracy: 0.6316\n",
      "Epoch 258/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3126 - accuracy: 0.8592 - val_loss: 0.8215 - val_accuracy: 0.6316\n",
      "Epoch 259/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.3126 - accuracy: 0.8592 - val_loss: 0.8215 - val_accuracy: 0.6316\n",
      "Epoch 260/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.3117 - accuracy: 0.8556 - val_loss: 0.8207 - val_accuracy: 0.6316\n",
      "Epoch 261/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3110 - accuracy: 0.8592 - val_loss: 0.8230 - val_accuracy: 0.6316\n",
      "Epoch 262/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3106 - accuracy: 0.8627 - val_loss: 0.8254 - val_accuracy: 0.6316\n",
      "Epoch 263/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3099 - accuracy: 0.8662 - val_loss: 0.8276 - val_accuracy: 0.6316\n",
      "Epoch 264/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3094 - accuracy: 0.8627 - val_loss: 0.8302 - val_accuracy: 0.6316\n",
      "Epoch 265/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.3091 - accuracy: 0.8627 - val_loss: 0.8286 - val_accuracy: 0.6316\n",
      "Epoch 266/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.3085 - accuracy: 0.8627 - val_loss: 0.8290 - val_accuracy: 0.6316\n",
      "Epoch 267/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3075 - accuracy: 0.8627 - val_loss: 0.8322 - val_accuracy: 0.6316\n",
      "Epoch 268/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.3072 - accuracy: 0.8662 - val_loss: 0.8318 - val_accuracy: 0.6316\n",
      "Epoch 269/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3067 - accuracy: 0.8697 - val_loss: 0.8322 - val_accuracy: 0.6316\n",
      "Epoch 270/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.3062 - accuracy: 0.8662 - val_loss: 0.8303 - val_accuracy: 0.6316\n",
      "Epoch 271/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.3055 - accuracy: 0.8592 - val_loss: 0.8344 - val_accuracy: 0.6316\n",
      "Epoch 272/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3050 - accuracy: 0.8697 - val_loss: 0.8351 - val_accuracy: 0.6316\n",
      "Epoch 273/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3043 - accuracy: 0.8732 - val_loss: 0.8364 - val_accuracy: 0.6316\n",
      "Epoch 274/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.3041 - accuracy: 0.8592 - val_loss: 0.8363 - val_accuracy: 0.6316\n",
      "Epoch 275/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.3033 - accuracy: 0.8662 - val_loss: 0.8449 - val_accuracy: 0.6316\n",
      "Epoch 276/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3028 - accuracy: 0.8662 - val_loss: 0.8591 - val_accuracy: 0.6316\n",
      "Epoch 277/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.3022 - accuracy: 0.8697 - val_loss: 0.8592 - val_accuracy: 0.6316\n",
      "Epoch 278/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.3020 - accuracy: 0.8697 - val_loss: 0.8560 - val_accuracy: 0.6316\n",
      "Epoch 279/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.3013 - accuracy: 0.8627 - val_loss: 0.9534 - val_accuracy: 0.6316\n",
      "Epoch 280/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.3007 - accuracy: 0.8662 - val_loss: 0.8884 - val_accuracy: 0.6316\n",
      "Epoch 281/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.3004 - accuracy: 0.8662 - val_loss: 0.9563 - val_accuracy: 0.6316\n",
      "Epoch 282/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2998 - accuracy: 0.8697 - val_loss: 0.9532 - val_accuracy: 0.6316\n",
      "Epoch 283/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2990 - accuracy: 0.8732 - val_loss: 0.9530 - val_accuracy: 0.6316\n",
      "Epoch 284/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.2986 - accuracy: 0.8732 - val_loss: 0.9530 - val_accuracy: 0.6316\n",
      "Epoch 285/500\n",
      "284/284 [==============================] - 0s 163us/sample - loss: 0.2981 - accuracy: 0.8732 - val_loss: 0.9558 - val_accuracy: 0.6316\n",
      "Epoch 286/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2976 - accuracy: 0.8697 - val_loss: 0.9594 - val_accuracy: 0.6316\n",
      "Epoch 287/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2972 - accuracy: 0.8732 - val_loss: 0.9556 - val_accuracy: 0.6316\n",
      "Epoch 288/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2967 - accuracy: 0.8697 - val_loss: 0.9593 - val_accuracy: 0.6316\n",
      "Epoch 289/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2960 - accuracy: 0.8732 - val_loss: 0.9596 - val_accuracy: 0.6316\n",
      "Epoch 290/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2955 - accuracy: 0.8732 - val_loss: 0.9600 - val_accuracy: 0.6316\n",
      "Epoch 291/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2949 - accuracy: 0.8697 - val_loss: 0.9598 - val_accuracy: 0.6316\n",
      "Epoch 292/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2947 - accuracy: 0.8732 - val_loss: 0.9637 - val_accuracy: 0.6316\n",
      "Epoch 293/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2945 - accuracy: 0.8697 - val_loss: 0.9664 - val_accuracy: 0.6316\n",
      "Epoch 294/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2935 - accuracy: 0.8697 - val_loss: 0.9671 - val_accuracy: 0.6316\n",
      "Epoch 295/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2931 - accuracy: 0.8732 - val_loss: 0.9684 - val_accuracy: 0.6316\n",
      "Epoch 296/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2925 - accuracy: 0.8697 - val_loss: 0.9629 - val_accuracy: 0.6316\n",
      "Epoch 297/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2921 - accuracy: 0.8732 - val_loss: 0.9672 - val_accuracy: 0.6316\n",
      "Epoch 298/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2917 - accuracy: 0.8732 - val_loss: 0.9695 - val_accuracy: 0.6316\n",
      "Epoch 299/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2910 - accuracy: 0.8697 - val_loss: 0.9753 - val_accuracy: 0.6316\n",
      "Epoch 300/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2906 - accuracy: 0.8697 - val_loss: 0.9764 - val_accuracy: 0.6316\n",
      "Epoch 301/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2899 - accuracy: 0.8697 - val_loss: 0.9759 - val_accuracy: 0.6316\n",
      "Epoch 302/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2896 - accuracy: 0.8732 - val_loss: 1.0776 - val_accuracy: 0.6316\n",
      "Epoch 303/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2891 - accuracy: 0.8697 - val_loss: 1.0775 - val_accuracy: 0.6316\n",
      "Epoch 304/500\n",
      "284/284 [==============================] - 0s 188us/sample - loss: 0.2885 - accuracy: 0.8697 - val_loss: 0.9932 - val_accuracy: 0.6316\n",
      "Epoch 305/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2879 - accuracy: 0.8732 - val_loss: 1.0779 - val_accuracy: 0.6316\n",
      "Epoch 306/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2877 - accuracy: 0.8697 - val_loss: 1.0777 - val_accuracy: 0.6316\n",
      "Epoch 307/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2871 - accuracy: 0.8732 - val_loss: 1.0772 - val_accuracy: 0.6316\n",
      "Epoch 308/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2866 - accuracy: 0.8697 - val_loss: 1.0773 - val_accuracy: 0.6316\n",
      "Epoch 309/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.2858 - accuracy: 0.8732 - val_loss: 1.0771 - val_accuracy: 0.6316\n",
      "Epoch 310/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2855 - accuracy: 0.8697 - val_loss: 1.0775 - val_accuracy: 0.6316\n",
      "Epoch 311/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2854 - accuracy: 0.8732 - val_loss: 1.0779 - val_accuracy: 0.6316\n",
      "Epoch 312/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2846 - accuracy: 0.8768 - val_loss: 1.0786 - val_accuracy: 0.6316\n",
      "Epoch 313/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2842 - accuracy: 0.8697 - val_loss: 1.0791 - val_accuracy: 0.6316\n",
      "Epoch 314/500\n",
      "284/284 [==============================] - 0s 144us/sample - loss: 0.2839 - accuracy: 0.8732 - val_loss: 1.0796 - val_accuracy: 0.6316\n",
      "Epoch 315/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2832 - accuracy: 0.8732 - val_loss: 1.0802 - val_accuracy: 0.6316\n",
      "Epoch 316/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2827 - accuracy: 0.8768 - val_loss: 1.0797 - val_accuracy: 0.6316\n",
      "Epoch 317/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2825 - accuracy: 0.8768 - val_loss: 1.0795 - val_accuracy: 0.6316\n",
      "Epoch 318/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2816 - accuracy: 0.8803 - val_loss: 1.0796 - val_accuracy: 0.6316\n",
      "Epoch 319/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2812 - accuracy: 0.8732 - val_loss: 1.0809 - val_accuracy: 0.6316\n",
      "Epoch 320/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2807 - accuracy: 0.8803 - val_loss: 1.0800 - val_accuracy: 0.6316\n",
      "Epoch 321/500\n",
      "284/284 [==============================] - 0s 141us/sample - loss: 0.2803 - accuracy: 0.8768 - val_loss: 1.0809 - val_accuracy: 0.6316\n",
      "Epoch 322/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2796 - accuracy: 0.8732 - val_loss: 1.0808 - val_accuracy: 0.6316\n",
      "Epoch 323/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2790 - accuracy: 0.8768 - val_loss: 1.0819 - val_accuracy: 0.6316\n",
      "Epoch 324/500\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.81 - 0s 158us/sample - loss: 0.2787 - accuracy: 0.8768 - val_loss: 1.0836 - val_accuracy: 0.6316\n",
      "Epoch 325/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2783 - accuracy: 0.8768 - val_loss: 1.0831 - val_accuracy: 0.6316\n",
      "Epoch 326/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2776 - accuracy: 0.8768 - val_loss: 1.0823 - val_accuracy: 0.6316\n",
      "Epoch 327/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2772 - accuracy: 0.8768 - val_loss: 1.0837 - val_accuracy: 0.6316\n",
      "Epoch 328/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2770 - accuracy: 0.8803 - val_loss: 1.0826 - val_accuracy: 0.6316\n",
      "Epoch 329/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2764 - accuracy: 0.8803 - val_loss: 1.0843 - val_accuracy: 0.6316\n",
      "Epoch 330/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.2766 - accuracy: 0.8768 - val_loss: 1.0840 - val_accuracy: 0.6316\n",
      "Epoch 331/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2755 - accuracy: 0.8803 - val_loss: 1.0827 - val_accuracy: 0.6316\n",
      "Epoch 332/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2748 - accuracy: 0.8768 - val_loss: 1.0843 - val_accuracy: 0.6316\n",
      "Epoch 333/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2747 - accuracy: 0.8803 - val_loss: 1.0843 - val_accuracy: 0.6316\n",
      "Epoch 334/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2739 - accuracy: 0.8803 - val_loss: 1.0837 - val_accuracy: 0.6316\n",
      "Epoch 335/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2734 - accuracy: 0.8768 - val_loss: 1.0854 - val_accuracy: 0.6316\n",
      "Epoch 336/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2733 - accuracy: 0.8768 - val_loss: 1.0864 - val_accuracy: 0.6316\n",
      "Epoch 337/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2728 - accuracy: 0.8803 - val_loss: 1.0866 - val_accuracy: 0.6316\n",
      "Epoch 338/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2722 - accuracy: 0.8803 - val_loss: 1.0872 - val_accuracy: 0.6316\n",
      "Epoch 339/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2718 - accuracy: 0.8803 - val_loss: 1.0877 - val_accuracy: 0.6316\n",
      "Epoch 340/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2712 - accuracy: 0.8838 - val_loss: 1.0877 - val_accuracy: 0.6316\n",
      "Epoch 341/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2710 - accuracy: 0.8803 - val_loss: 1.0878 - val_accuracy: 0.6316\n",
      "Epoch 342/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2705 - accuracy: 0.8803 - val_loss: 1.0883 - val_accuracy: 0.6316\n",
      "Epoch 343/500\n",
      "284/284 [==============================] - 0s 177us/sample - loss: 0.2697 - accuracy: 0.8803 - val_loss: 1.0880 - val_accuracy: 0.6316\n",
      "Epoch 344/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2692 - accuracy: 0.8838 - val_loss: 1.0887 - val_accuracy: 0.6316\n",
      "Epoch 345/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2690 - accuracy: 0.8838 - val_loss: 1.0893 - val_accuracy: 0.6316\n",
      "Epoch 346/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2688 - accuracy: 0.8803 - val_loss: 1.0885 - val_accuracy: 0.6211\n",
      "Epoch 347/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2682 - accuracy: 0.8838 - val_loss: 1.0894 - val_accuracy: 0.6316\n",
      "Epoch 348/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2676 - accuracy: 0.8838 - val_loss: 1.0881 - val_accuracy: 0.6211\n",
      "Epoch 349/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2673 - accuracy: 0.8803 - val_loss: 1.0891 - val_accuracy: 0.6211\n",
      "Epoch 350/500\n",
      "284/284 [==============================] - 0s 245us/sample - loss: 0.2667 - accuracy: 0.8838 - val_loss: 1.0900 - val_accuracy: 0.6211\n",
      "Epoch 351/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2667 - accuracy: 0.8838 - val_loss: 1.0895 - val_accuracy: 0.6316\n",
      "Epoch 352/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2660 - accuracy: 0.8803 - val_loss: 1.0898 - val_accuracy: 0.6211\n",
      "Epoch 353/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2654 - accuracy: 0.8803 - val_loss: 1.0895 - val_accuracy: 0.6211\n",
      "Epoch 354/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2651 - accuracy: 0.8838 - val_loss: 1.0888 - val_accuracy: 0.6211\n",
      "Epoch 355/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.2645 - accuracy: 0.8838 - val_loss: 1.0909 - val_accuracy: 0.6211\n",
      "Epoch 356/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2643 - accuracy: 0.8803 - val_loss: 1.0897 - val_accuracy: 0.6211\n",
      "Epoch 357/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.2635 - accuracy: 0.8838 - val_loss: 1.0904 - val_accuracy: 0.6211\n",
      "Epoch 358/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2631 - accuracy: 0.8838 - val_loss: 1.0890 - val_accuracy: 0.6211\n",
      "Epoch 359/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2628 - accuracy: 0.8838 - val_loss: 1.0908 - val_accuracy: 0.6211\n",
      "Epoch 360/500\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.90 - 0s 215us/sample - loss: 0.2623 - accuracy: 0.8838 - val_loss: 1.0900 - val_accuracy: 0.6211\n",
      "Epoch 361/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.2620 - accuracy: 0.8838 - val_loss: 1.0910 - val_accuracy: 0.6211\n",
      "Epoch 362/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.2614 - accuracy: 0.8838 - val_loss: 1.0915 - val_accuracy: 0.6211\n",
      "Epoch 363/500\n",
      "284/284 [==============================] - 0s 222us/sample - loss: 0.2608 - accuracy: 0.8838 - val_loss: 1.0920 - val_accuracy: 0.6211\n",
      "Epoch 364/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2607 - accuracy: 0.8838 - val_loss: 1.0933 - val_accuracy: 0.6211\n",
      "Epoch 365/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2604 - accuracy: 0.8838 - val_loss: 1.0936 - val_accuracy: 0.6211\n",
      "Epoch 366/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.2601 - accuracy: 0.8838 - val_loss: 1.0917 - val_accuracy: 0.6211\n",
      "Epoch 367/500\n",
      "284/284 [==============================] - 0s 232us/sample - loss: 0.2591 - accuracy: 0.8838 - val_loss: 1.0915 - val_accuracy: 0.6211\n",
      "Epoch 368/500\n",
      "284/284 [==============================] - 0s 313us/sample - loss: 0.2590 - accuracy: 0.8838 - val_loss: 1.0922 - val_accuracy: 0.6211\n",
      "Epoch 369/500\n",
      "284/284 [==============================] - 0s 236us/sample - loss: 0.2587 - accuracy: 0.8838 - val_loss: 1.0928 - val_accuracy: 0.6211\n",
      "Epoch 370/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.2582 - accuracy: 0.8838 - val_loss: 1.0928 - val_accuracy: 0.6211\n",
      "Epoch 371/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.2575 - accuracy: 0.8838 - val_loss: 1.0936 - val_accuracy: 0.6211\n",
      "Epoch 372/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.2572 - accuracy: 0.8838 - val_loss: 1.0933 - val_accuracy: 0.6211\n",
      "Epoch 373/500\n",
      "284/284 [==============================] - 0s 222us/sample - loss: 0.2567 - accuracy: 0.8838 - val_loss: 1.0937 - val_accuracy: 0.6211\n",
      "Epoch 374/500\n",
      "284/284 [==============================] - 0s 222us/sample - loss: 0.2565 - accuracy: 0.8838 - val_loss: 1.0961 - val_accuracy: 0.6211\n",
      "Epoch 375/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.2560 - accuracy: 0.8838 - val_loss: 1.0955 - val_accuracy: 0.6211\n",
      "Epoch 376/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.2556 - accuracy: 0.8838 - val_loss: 1.0953 - val_accuracy: 0.6211\n",
      "Epoch 377/500\n",
      "284/284 [==============================] - 0s 313us/sample - loss: 0.2552 - accuracy: 0.8838 - val_loss: 1.0949 - val_accuracy: 0.6211\n",
      "Epoch 378/500\n",
      "284/284 [==============================] - 0s 415us/sample - loss: 0.2548 - accuracy: 0.8838 - val_loss: 1.0945 - val_accuracy: 0.6211\n",
      "Epoch 379/500\n",
      "284/284 [==============================] - 0s 292us/sample - loss: 0.2544 - accuracy: 0.8873 - val_loss: 1.0937 - val_accuracy: 0.6211\n",
      "Epoch 380/500\n",
      "284/284 [==============================] - 0s 267us/sample - loss: 0.2542 - accuracy: 0.8873 - val_loss: 1.0957 - val_accuracy: 0.6211\n",
      "Epoch 381/500\n",
      "284/284 [==============================] - 0s 229us/sample - loss: 0.2536 - accuracy: 0.8838 - val_loss: 1.0964 - val_accuracy: 0.6211\n",
      "Epoch 382/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2529 - accuracy: 0.8838 - val_loss: 1.0958 - val_accuracy: 0.6211\n",
      "Epoch 383/500\n",
      "284/284 [==============================] - 0s 317us/sample - loss: 0.2527 - accuracy: 0.8873 - val_loss: 1.0961 - val_accuracy: 0.6211\n",
      "Epoch 384/500\n",
      "284/284 [==============================] - 0s 253us/sample - loss: 0.2520 - accuracy: 0.8873 - val_loss: 1.0970 - val_accuracy: 0.6211\n",
      "Epoch 385/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2519 - accuracy: 0.8873 - val_loss: 1.0963 - val_accuracy: 0.6211\n",
      "Epoch 386/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2514 - accuracy: 0.8873 - val_loss: 1.0961 - val_accuracy: 0.6211\n",
      "Epoch 387/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2511 - accuracy: 0.8838 - val_loss: 1.0957 - val_accuracy: 0.6211\n",
      "Epoch 388/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2506 - accuracy: 0.8908 - val_loss: 1.0963 - val_accuracy: 0.6211\n",
      "Epoch 389/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2502 - accuracy: 0.8908 - val_loss: 1.0967 - val_accuracy: 0.6211\n",
      "Epoch 390/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2496 - accuracy: 0.8908 - val_loss: 1.0972 - val_accuracy: 0.6211\n",
      "Epoch 391/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2494 - accuracy: 0.8873 - val_loss: 1.0967 - val_accuracy: 0.6211\n",
      "Epoch 392/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.2489 - accuracy: 0.8908 - val_loss: 1.0973 - val_accuracy: 0.6211\n",
      "Epoch 393/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2487 - accuracy: 0.8908 - val_loss: 1.0973 - val_accuracy: 0.6211\n",
      "Epoch 394/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2483 - accuracy: 0.8908 - val_loss: 1.0966 - val_accuracy: 0.6211\n",
      "Epoch 395/500\n",
      "284/284 [==============================] - 0s 204us/sample - loss: 0.2477 - accuracy: 0.8908 - val_loss: 1.0982 - val_accuracy: 0.6211\n",
      "Epoch 396/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2474 - accuracy: 0.8873 - val_loss: 1.0974 - val_accuracy: 0.6211\n",
      "Epoch 397/500\n",
      "284/284 [==============================] - 0s 264us/sample - loss: 0.2470 - accuracy: 0.8908 - val_loss: 1.0975 - val_accuracy: 0.6211\n",
      "Epoch 398/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2466 - accuracy: 0.8908 - val_loss: 1.0983 - val_accuracy: 0.6211\n",
      "Epoch 399/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2465 - accuracy: 0.8908 - val_loss: 1.0973 - val_accuracy: 0.6211\n",
      "Epoch 400/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2462 - accuracy: 0.8908 - val_loss: 1.0987 - val_accuracy: 0.6211\n",
      "Epoch 401/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2455 - accuracy: 0.8908 - val_loss: 1.0983 - val_accuracy: 0.6211\n",
      "Epoch 402/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2450 - accuracy: 0.8908 - val_loss: 1.0987 - val_accuracy: 0.6211\n",
      "Epoch 403/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2443 - accuracy: 0.8908 - val_loss: 1.0979 - val_accuracy: 0.6211\n",
      "Epoch 404/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.2441 - accuracy: 0.8908 - val_loss: 1.0986 - val_accuracy: 0.6211\n",
      "Epoch 405/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2439 - accuracy: 0.8908 - val_loss: 1.0977 - val_accuracy: 0.6211\n",
      "Epoch 406/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2438 - accuracy: 0.8908 - val_loss: 1.0997 - val_accuracy: 0.6211\n",
      "Epoch 407/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2432 - accuracy: 0.8908 - val_loss: 1.1003 - val_accuracy: 0.6211\n",
      "Epoch 408/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2427 - accuracy: 0.8908 - val_loss: 1.0998 - val_accuracy: 0.6211\n",
      "Epoch 409/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2420 - accuracy: 0.8908 - val_loss: 1.1002 - val_accuracy: 0.6211\n",
      "Epoch 410/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2421 - accuracy: 0.8908 - val_loss: 1.1001 - val_accuracy: 0.6211\n",
      "Epoch 411/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2413 - accuracy: 0.8908 - val_loss: 1.0991 - val_accuracy: 0.6211\n",
      "Epoch 412/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2412 - accuracy: 0.8908 - val_loss: 1.0999 - val_accuracy: 0.6211\n",
      "Epoch 413/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2405 - accuracy: 0.8908 - val_loss: 1.1014 - val_accuracy: 0.6211\n",
      "Epoch 414/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2403 - accuracy: 0.8908 - val_loss: 1.1030 - val_accuracy: 0.6211\n",
      "Epoch 415/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2400 - accuracy: 0.8908 - val_loss: 1.1019 - val_accuracy: 0.6211\n",
      "Epoch 416/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2394 - accuracy: 0.8944 - val_loss: 1.1009 - val_accuracy: 0.6211\n",
      "Epoch 417/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2393 - accuracy: 0.8908 - val_loss: 1.1002 - val_accuracy: 0.6211\n",
      "Epoch 418/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2389 - accuracy: 0.8908 - val_loss: 1.1022 - val_accuracy: 0.6211\n",
      "Epoch 419/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2384 - accuracy: 0.8944 - val_loss: 1.1013 - val_accuracy: 0.6211\n",
      "Epoch 420/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2380 - accuracy: 0.8908 - val_loss: 1.1022 - val_accuracy: 0.6211\n",
      "Epoch 421/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2376 - accuracy: 0.8944 - val_loss: 1.1009 - val_accuracy: 0.6211\n",
      "Epoch 422/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2373 - accuracy: 0.8908 - val_loss: 1.1020 - val_accuracy: 0.6211\n",
      "Epoch 423/500\n",
      "284/284 [==============================] - 0s 160us/sample - loss: 0.2368 - accuracy: 0.8908 - val_loss: 1.1022 - val_accuracy: 0.6211\n",
      "Epoch 424/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2366 - accuracy: 0.8908 - val_loss: 1.1023 - val_accuracy: 0.6211\n",
      "Epoch 425/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2360 - accuracy: 0.8979 - val_loss: 1.1032 - val_accuracy: 0.6211\n",
      "Epoch 426/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2355 - accuracy: 0.8979 - val_loss: 1.1029 - val_accuracy: 0.6211\n",
      "Epoch 427/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2353 - accuracy: 0.8944 - val_loss: 1.1028 - val_accuracy: 0.6211\n",
      "Epoch 428/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2351 - accuracy: 0.8979 - val_loss: 1.1034 - val_accuracy: 0.6211\n",
      "Epoch 429/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2343 - accuracy: 0.8979 - val_loss: 1.1044 - val_accuracy: 0.6211\n",
      "Epoch 430/500\n",
      "284/284 [==============================] - 0s 194us/sample - loss: 0.2342 - accuracy: 0.8908 - val_loss: 1.1054 - val_accuracy: 0.6211\n",
      "Epoch 431/500\n",
      "284/284 [==============================] - 0s 197us/sample - loss: 0.2339 - accuracy: 0.8979 - val_loss: 1.1050 - val_accuracy: 0.6211\n",
      "Epoch 432/500\n",
      "284/284 [==============================] - 0s 225us/sample - loss: 0.2336 - accuracy: 0.8944 - val_loss: 1.1045 - val_accuracy: 0.6211\n",
      "Epoch 433/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2332 - accuracy: 0.8944 - val_loss: 1.1035 - val_accuracy: 0.6211\n",
      "Epoch 434/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2329 - accuracy: 0.8979 - val_loss: 1.1043 - val_accuracy: 0.6211\n",
      "Epoch 435/500\n",
      "284/284 [==============================] - 0s 208us/sample - loss: 0.2324 - accuracy: 0.8944 - val_loss: 1.1047 - val_accuracy: 0.6211\n",
      "Epoch 436/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2319 - accuracy: 0.8979 - val_loss: 1.1041 - val_accuracy: 0.6211\n",
      "Epoch 437/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2316 - accuracy: 0.9014 - val_loss: 1.1061 - val_accuracy: 0.6105\n",
      "Epoch 438/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2314 - accuracy: 0.8979 - val_loss: 1.1068 - val_accuracy: 0.6105\n",
      "Epoch 439/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2308 - accuracy: 0.8979 - val_loss: 1.1076 - val_accuracy: 0.6211\n",
      "Epoch 440/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.2306 - accuracy: 0.8944 - val_loss: 1.1062 - val_accuracy: 0.6211\n",
      "Epoch 441/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2299 - accuracy: 0.8979 - val_loss: 1.1077 - val_accuracy: 0.6105\n",
      "Epoch 442/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2298 - accuracy: 0.8944 - val_loss: 1.1080 - val_accuracy: 0.6105\n",
      "Epoch 443/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2293 - accuracy: 0.8979 - val_loss: 1.1080 - val_accuracy: 0.6105\n",
      "Epoch 444/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2290 - accuracy: 0.8979 - val_loss: 1.1090 - val_accuracy: 0.6105\n",
      "Epoch 445/500\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 0.2288 - accuracy: 0.8944 - val_loss: 1.1082 - val_accuracy: 0.6105\n",
      "Epoch 446/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2282 - accuracy: 0.8979 - val_loss: 1.1083 - val_accuracy: 0.6105\n",
      "Epoch 447/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2281 - accuracy: 0.9014 - val_loss: 1.1105 - val_accuracy: 0.6105\n",
      "Epoch 448/500\n",
      "284/284 [==============================] - 0s 148us/sample - loss: 0.2277 - accuracy: 0.8979 - val_loss: 1.1102 - val_accuracy: 0.6105\n",
      "Epoch 449/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2271 - accuracy: 0.8979 - val_loss: 1.1079 - val_accuracy: 0.6105\n",
      "Epoch 450/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2271 - accuracy: 0.9014 - val_loss: 1.1089 - val_accuracy: 0.6211\n",
      "Epoch 451/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2267 - accuracy: 0.9014 - val_loss: 1.1084 - val_accuracy: 0.6211\n",
      "Epoch 452/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2260 - accuracy: 0.8979 - val_loss: 1.1104 - val_accuracy: 0.6211\n",
      "Epoch 453/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2258 - accuracy: 0.9014 - val_loss: 1.1098 - val_accuracy: 0.6211\n",
      "Epoch 454/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2252 - accuracy: 0.9014 - val_loss: 1.1113 - val_accuracy: 0.6211\n",
      "Epoch 455/500\n",
      "284/284 [==============================] - 0s 211us/sample - loss: 0.2249 - accuracy: 0.9014 - val_loss: 1.1104 - val_accuracy: 0.6211\n",
      "Epoch 456/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2247 - accuracy: 0.9049 - val_loss: 1.1109 - val_accuracy: 0.6211\n",
      "Epoch 457/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2241 - accuracy: 0.9049 - val_loss: 1.1113 - val_accuracy: 0.6211\n",
      "Epoch 458/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2240 - accuracy: 0.9049 - val_loss: 1.1114 - val_accuracy: 0.6211\n",
      "Epoch 459/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2237 - accuracy: 0.9014 - val_loss: 1.1130 - val_accuracy: 0.6105\n",
      "Epoch 460/500\n",
      "284/284 [==============================] - 0s 176us/sample - loss: 0.2232 - accuracy: 0.9049 - val_loss: 1.1130 - val_accuracy: 0.6105\n",
      "Epoch 461/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2227 - accuracy: 0.9014 - val_loss: 1.1128 - val_accuracy: 0.6105\n",
      "Epoch 462/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2227 - accuracy: 0.9049 - val_loss: 1.1135 - val_accuracy: 0.6105\n",
      "Epoch 463/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2222 - accuracy: 0.9014 - val_loss: 1.1134 - val_accuracy: 0.6105\n",
      "Epoch 464/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2220 - accuracy: 0.9049 - val_loss: 1.1133 - val_accuracy: 0.6105\n",
      "Epoch 465/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2217 - accuracy: 0.9049 - val_loss: 1.1130 - val_accuracy: 0.6105\n",
      "Epoch 466/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2211 - accuracy: 0.9049 - val_loss: 1.1137 - val_accuracy: 0.6105\n",
      "Epoch 467/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2210 - accuracy: 0.9049 - val_loss: 1.1142 - val_accuracy: 0.6105\n",
      "Epoch 468/500\n",
      "284/284 [==============================] - 0s 172us/sample - loss: 0.2205 - accuracy: 0.9049 - val_loss: 1.1150 - val_accuracy: 0.6105\n",
      "Epoch 469/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2200 - accuracy: 0.9049 - val_loss: 1.1152 - val_accuracy: 0.6105\n",
      "Epoch 470/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2199 - accuracy: 0.9049 - val_loss: 1.1136 - val_accuracy: 0.6105\n",
      "Epoch 471/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2195 - accuracy: 0.9049 - val_loss: 1.1150 - val_accuracy: 0.6105\n",
      "Epoch 472/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2193 - accuracy: 0.9085 - val_loss: 1.1155 - val_accuracy: 0.6105\n",
      "Epoch 473/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2188 - accuracy: 0.9085 - val_loss: 1.1170 - val_accuracy: 0.6105\n",
      "Epoch 474/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2183 - accuracy: 0.9085 - val_loss: 1.1159 - val_accuracy: 0.6105\n",
      "Epoch 475/500\n",
      "284/284 [==============================] - 0s 190us/sample - loss: 0.2182 - accuracy: 0.9049 - val_loss: 1.1148 - val_accuracy: 0.6105\n",
      "Epoch 476/500\n",
      "284/284 [==============================] - 0s 201us/sample - loss: 0.2175 - accuracy: 0.9085 - val_loss: 1.1157 - val_accuracy: 0.6105\n",
      "Epoch 477/500\n",
      "284/284 [==============================] - 0s 165us/sample - loss: 0.2176 - accuracy: 0.9120 - val_loss: 1.1180 - val_accuracy: 0.6105\n",
      "Epoch 478/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2171 - accuracy: 0.9120 - val_loss: 1.1169 - val_accuracy: 0.6105\n",
      "Epoch 479/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2167 - accuracy: 0.9085 - val_loss: 1.1169 - val_accuracy: 0.6105\n",
      "Epoch 480/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2164 - accuracy: 0.9120 - val_loss: 1.1190 - val_accuracy: 0.6105\n",
      "Epoch 481/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2160 - accuracy: 0.9120 - val_loss: 1.1171 - val_accuracy: 0.6105\n",
      "Epoch 482/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2158 - accuracy: 0.9085 - val_loss: 1.1163 - val_accuracy: 0.6105\n",
      "Epoch 483/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2152 - accuracy: 0.9155 - val_loss: 1.1178 - val_accuracy: 0.6105\n",
      "Epoch 484/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2149 - accuracy: 0.9085 - val_loss: 1.1170 - val_accuracy: 0.6105\n",
      "Epoch 485/500\n",
      "284/284 [==============================] - 0s 169us/sample - loss: 0.2146 - accuracy: 0.9120 - val_loss: 1.1185 - val_accuracy: 0.6105\n",
      "Epoch 486/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2144 - accuracy: 0.9085 - val_loss: 1.1175 - val_accuracy: 0.6105\n",
      "Epoch 487/500\n",
      "284/284 [==============================] - 0s 183us/sample - loss: 0.2139 - accuracy: 0.9120 - val_loss: 1.1197 - val_accuracy: 0.6105\n",
      "Epoch 488/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2136 - accuracy: 0.9085 - val_loss: 1.1194 - val_accuracy: 0.6105\n",
      "Epoch 489/500\n",
      "284/284 [==============================] - 0s 243us/sample - loss: 0.2132 - accuracy: 0.9120 - val_loss: 1.1208 - val_accuracy: 0.6105\n",
      "Epoch 490/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2129 - accuracy: 0.9120 - val_loss: 1.1206 - val_accuracy: 0.6105\n",
      "Epoch 491/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2126 - accuracy: 0.9120 - val_loss: 1.1203 - val_accuracy: 0.6105\n",
      "Epoch 492/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2122 - accuracy: 0.9120 - val_loss: 1.1207 - val_accuracy: 0.6105\n",
      "Epoch 493/500\n",
      "284/284 [==============================] - 0s 151us/sample - loss: 0.2119 - accuracy: 0.9120 - val_loss: 1.1208 - val_accuracy: 0.6105\n",
      "Epoch 494/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2116 - accuracy: 0.9120 - val_loss: 1.1196 - val_accuracy: 0.6105\n",
      "Epoch 495/500\n",
      "284/284 [==============================] - 0s 162us/sample - loss: 0.2113 - accuracy: 0.9120 - val_loss: 1.1208 - val_accuracy: 0.6105\n",
      "Epoch 496/500\n",
      "284/284 [==============================] - 0s 179us/sample - loss: 0.2108 - accuracy: 0.9120 - val_loss: 1.1213 - val_accuracy: 0.6105\n",
      "Epoch 497/500\n",
      "284/284 [==============================] - 0s 187us/sample - loss: 0.2106 - accuracy: 0.9120 - val_loss: 1.1206 - val_accuracy: 0.6105\n",
      "Epoch 498/500\n",
      "284/284 [==============================] - 0s 158us/sample - loss: 0.2102 - accuracy: 0.9120 - val_loss: 1.1211 - val_accuracy: 0.6105\n",
      "Epoch 499/500\n",
      "284/284 [==============================] - 0s 155us/sample - loss: 0.2097 - accuracy: 0.9155 - val_loss: 1.1229 - val_accuracy: 0.6105\n",
      "Epoch 500/500\n",
      "284/284 [==============================] - 0s 144us/sample - loss: 0.2097 - accuracy: 0.9120 - val_loss: 1.1216 - val_accuracy: 0.6105\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X_train, y_train, epochs=500,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 134us/sample - loss: 1.3339 - accuracy: 0.6850\n"
     ]
    }
   ],
   "source": [
    "mae_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [5.649278942967804,\n",
       "  4.085554613193995,\n",
       "  3.172165937826667,\n",
       "  2.4224908318318112,\n",
       "  1.695545947048026,\n",
       "  1.5870978211013365,\n",
       "  1.859735155609292,\n",
       "  0.9816555515141554,\n",
       "  0.7911195620684557,\n",
       "  0.765602749837956,\n",
       "  0.7510415735379071,\n",
       "  0.701247643417036,\n",
       "  0.6786629037118294,\n",
       "  0.6717465469534968,\n",
       "  0.6645582410651194,\n",
       "  0.6584482151018062,\n",
       "  0.6522741737500043,\n",
       "  0.646994626857865,\n",
       "  0.6413674430108406,\n",
       "  0.6360465422482557,\n",
       "  0.6310532437243932,\n",
       "  0.626581224757181,\n",
       "  0.621813908429213,\n",
       "  0.617646852849235,\n",
       "  0.6133384587059558,\n",
       "  0.6092758766362365,\n",
       "  0.6050368228428801,\n",
       "  0.6015280552313361,\n",
       "  0.597639391120051,\n",
       "  0.5937186320063094,\n",
       "  0.5909673563191589,\n",
       "  0.5871204121012084,\n",
       "  0.5835631531728825,\n",
       "  0.5800203563461841,\n",
       "  0.5772820031139213,\n",
       "  0.573939495523211,\n",
       "  0.5706619620323181,\n",
       "  0.5673725374147925,\n",
       "  0.5647230929052326,\n",
       "  0.5617473973354823,\n",
       "  0.5591755614314281,\n",
       "  0.5562666427921241,\n",
       "  0.5536997645673617,\n",
       "  0.5508069068613187,\n",
       "  0.5480399316465351,\n",
       "  0.5468138783750399,\n",
       "  0.543631567921437,\n",
       "  0.5408708125772611,\n",
       "  0.5385911447901122,\n",
       "  0.5362412367068546,\n",
       "  0.5334397722297991,\n",
       "  0.531518753145782,\n",
       "  0.5288510624791535,\n",
       "  0.5268264622755454,\n",
       "  0.5250345762346832,\n",
       "  0.5223629373899648,\n",
       "  0.5205454247098573,\n",
       "  0.5181394525816743,\n",
       "  0.5159759672594743,\n",
       "  0.5141939718118855,\n",
       "  0.5117822218109185,\n",
       "  0.5098311384798775,\n",
       "  0.508294788044943,\n",
       "  0.5059071686905874,\n",
       "  0.5041675559231933,\n",
       "  0.5023981290803828,\n",
       "  0.500670418772899,\n",
       "  0.4989975350843349,\n",
       "  0.4972377856012801,\n",
       "  0.4948604258013443,\n",
       "  0.4933480284583401,\n",
       "  0.4913327374928434,\n",
       "  0.4896162639201527,\n",
       "  0.4880884692702495,\n",
       "  0.48697060514503804,\n",
       "  0.48477497445025913,\n",
       "  0.48318843396616656,\n",
       "  0.48140106150801754,\n",
       "  0.4798493960373838,\n",
       "  0.47831030840605077,\n",
       "  0.4768654301132954,\n",
       "  0.4752264396405556,\n",
       "  0.473847787564909,\n",
       "  0.4723697862994503,\n",
       "  0.4702589155082971,\n",
       "  0.4691216135528726,\n",
       "  0.4671405847643463,\n",
       "  0.46608317485997375,\n",
       "  0.46439253948104214,\n",
       "  0.4629623743010239,\n",
       "  0.4612992586384357,\n",
       "  0.4602977322860503,\n",
       "  0.4583033419830698,\n",
       "  0.4571071078240032,\n",
       "  0.45599492544859227,\n",
       "  0.45416719812742423,\n",
       "  0.45314904333839956,\n",
       "  0.45177856171634834,\n",
       "  0.45007335971778545,\n",
       "  0.4489447373739431,\n",
       "  0.44762258966204144,\n",
       "  0.4459629071430421,\n",
       "  0.444620367087109,\n",
       "  0.44335874663272373,\n",
       "  0.44195679123972503,\n",
       "  0.440357076450133,\n",
       "  0.4389492625921545,\n",
       "  0.43819628928748655,\n",
       "  0.4367449040144262,\n",
       "  0.43541656119722716,\n",
       "  0.4343304927919952,\n",
       "  0.43267523864625207,\n",
       "  0.4318374298827749,\n",
       "  0.43041279156443096,\n",
       "  0.42930468748992595,\n",
       "  0.4277350969717536,\n",
       "  0.42676985557650177,\n",
       "  0.4252719883347901,\n",
       "  0.4240349077842605,\n",
       "  0.42309572201379586,\n",
       "  0.42208972363404823,\n",
       "  0.42053956381032165,\n",
       "  0.41977521945053425,\n",
       "  0.4185619434000741,\n",
       "  0.4177752825575815,\n",
       "  0.4157933638968938,\n",
       "  0.4152449499553358,\n",
       "  0.4138491321617449,\n",
       "  0.4131044258534069,\n",
       "  0.4113913522639745,\n",
       "  0.4103285867563436,\n",
       "  0.409675484811756,\n",
       "  0.4081782644063654,\n",
       "  0.40724300792519474,\n",
       "  0.40605616821369656,\n",
       "  0.4051734188073118,\n",
       "  0.4042688654342168,\n",
       "  0.4028123604579711,\n",
       "  0.40197877900701173,\n",
       "  0.40072896530930424,\n",
       "  0.4000115302247061,\n",
       "  0.39891076633627987,\n",
       "  0.39760478995215726,\n",
       "  0.39692128628072604,\n",
       "  0.39587994780338986,\n",
       "  0.394950914970586,\n",
       "  0.39388356955958087,\n",
       "  0.39265585239504425,\n",
       "  0.39156098726769567,\n",
       "  0.3912349288732233,\n",
       "  0.3898504703817233,\n",
       "  0.38928548760817083,\n",
       "  0.3885166368014376,\n",
       "  0.3872498781748221,\n",
       "  0.38675443849093477,\n",
       "  0.38556896380975214,\n",
       "  0.3843761707695437,\n",
       "  0.3836069648534479,\n",
       "  0.3826718867664606,\n",
       "  0.3824155742013958,\n",
       "  0.3807524837238688,\n",
       "  0.3800079952663099,\n",
       "  0.3790739959394428,\n",
       "  0.37872520257049885,\n",
       "  0.3772546246018208,\n",
       "  0.376341720282192,\n",
       "  0.37549874732192134,\n",
       "  0.3749437558818871,\n",
       "  0.373848363967009,\n",
       "  0.3727520444023777,\n",
       "  0.37253902663647287,\n",
       "  0.3715457030585114,\n",
       "  0.3705499436653836,\n",
       "  0.36964812790843804,\n",
       "  0.36876577054950554,\n",
       "  0.3681421678670695,\n",
       "  0.36715044396024354,\n",
       "  0.36620125636248524,\n",
       "  0.36521238886134727,\n",
       "  0.36450894491773256,\n",
       "  0.363813664711697,\n",
       "  0.3638266916845886,\n",
       "  0.3620333709347416,\n",
       "  0.36154783989342165,\n",
       "  0.3604164089955075,\n",
       "  0.3597500660050083,\n",
       "  0.3589053342879658,\n",
       "  0.3580934485079537,\n",
       "  0.35761559723128733,\n",
       "  0.35656697187625186,\n",
       "  0.3557766256198077,\n",
       "  0.3552538274039685,\n",
       "  0.3545475484619678,\n",
       "  0.3537948274276626,\n",
       "  0.35298986418146483,\n",
       "  0.35251113100790643,\n",
       "  0.3516144588799544,\n",
       "  0.35059192189028565,\n",
       "  0.35017445977305023,\n",
       "  0.34919474746139956,\n",
       "  0.3487937089423059,\n",
       "  0.3480687078455804,\n",
       "  0.34765042679410585,\n",
       "  0.34651195373333676,\n",
       "  0.3457461352079687,\n",
       "  0.34517183731979045,\n",
       "  0.34436145676693447,\n",
       "  0.3440072167087609,\n",
       "  0.3431187998241102,\n",
       "  0.34260848542334327,\n",
       "  0.3418740277558985,\n",
       "  0.34130786086471987,\n",
       "  0.34058745394290335,\n",
       "  0.33992991942754935,\n",
       "  0.33907249401992473,\n",
       "  0.3387959914308199,\n",
       "  0.33768288098590477,\n",
       "  0.33702916284682044,\n",
       "  0.3362873989931295,\n",
       "  0.3356266349134311,\n",
       "  0.3353559739992652,\n",
       "  0.33465353535934234,\n",
       "  0.333968332955535,\n",
       "  0.33326856812960665,\n",
       "  0.33256173553601115,\n",
       "  0.33182751502789243,\n",
       "  0.33093000675590944,\n",
       "  0.3308350830010965,\n",
       "  0.32988978229777915,\n",
       "  0.3293832532117065,\n",
       "  0.32891016023259767,\n",
       "  0.3279588451267968,\n",
       "  0.32812681584291054,\n",
       "  0.3271185277213513,\n",
       "  0.3264824533966226,\n",
       "  0.3255892320418022,\n",
       "  0.32538496314639775,\n",
       "  0.32477468629957923,\n",
       "  0.3236821864692258,\n",
       "  0.3234060759275732,\n",
       "  0.32285873654862524,\n",
       "  0.3221554550486551,\n",
       "  0.32132794004930576,\n",
       "  0.3208164948392922,\n",
       "  0.3207854527822683,\n",
       "  0.3198620213169447,\n",
       "  0.3189099833998882,\n",
       "  0.31874363061407923,\n",
       "  0.3178142334373904,\n",
       "  0.3173100465620068,\n",
       "  0.31774327599666485,\n",
       "  0.3162976692260151,\n",
       "  0.31582721983882744,\n",
       "  0.3151938552168054,\n",
       "  0.3145475966829649,\n",
       "  0.3139604682653723,\n",
       "  0.3131709615109672,\n",
       "  0.3125841890422391,\n",
       "  0.3125706218497854,\n",
       "  0.3116874879514667,\n",
       "  0.3109578083098774,\n",
       "  0.31060562251319346,\n",
       "  0.30993302397325007,\n",
       "  0.30942109311130683,\n",
       "  0.30914915783304564,\n",
       "  0.3085402636460855,\n",
       "  0.30754226614052144,\n",
       "  0.30724258070260707,\n",
       "  0.306704066588845,\n",
       "  0.3061604676112323,\n",
       "  0.3055114359922812,\n",
       "  0.30501124955398934,\n",
       "  0.304259438330019,\n",
       "  0.3040527101133911,\n",
       "  0.30330666395979866,\n",
       "  0.3027572623440917,\n",
       "  0.302198716872175,\n",
       "  0.30197088567303937,\n",
       "  0.3013295959418928,\n",
       "  0.30072494732661986,\n",
       "  0.30038883862361104,\n",
       "  0.2998338413070625,\n",
       "  0.2990337740367567,\n",
       "  0.29858426434893004,\n",
       "  0.2980856887051757,\n",
       "  0.2975740151506075,\n",
       "  0.29720288557066044,\n",
       "  0.29671366365862567,\n",
       "  0.2960476594071993,\n",
       "  0.2954861360116744,\n",
       "  0.2949007598447128,\n",
       "  0.2947462889510141,\n",
       "  0.2944817966978315,\n",
       "  0.2935121113985357,\n",
       "  0.29307143537091535,\n",
       "  0.292486063821215,\n",
       "  0.29214846815021944,\n",
       "  0.291749571410703,\n",
       "  0.2909923498059662,\n",
       "  0.29057041734037264,\n",
       "  0.28987839985901204,\n",
       "  0.2895769934419175,\n",
       "  0.289085984439917,\n",
       "  0.28847000212736534,\n",
       "  0.2879301024154878,\n",
       "  0.287651389837265,\n",
       "  0.2870557958811102,\n",
       "  0.2865657546150852,\n",
       "  0.28583732142414847,\n",
       "  0.28549190852004036,\n",
       "  0.2853580037472953,\n",
       "  0.28459099354878276,\n",
       "  0.2842316037752259,\n",
       "  0.28391580472529776,\n",
       "  0.2831522583121985,\n",
       "  0.28267499720546563,\n",
       "  0.28249654173851013,\n",
       "  0.28158304494031716,\n",
       "  0.28118564839094456,\n",
       "  0.2806951953491694,\n",
       "  0.28027712354357814,\n",
       "  0.2795968299180689,\n",
       "  0.27899131808482425,\n",
       "  0.27874644919180536,\n",
       "  0.2782662443711724,\n",
       "  0.2775763344596809,\n",
       "  0.2772373527708188,\n",
       "  0.2769696506815897,\n",
       "  0.2763764029237586,\n",
       "  0.27659242002057355,\n",
       "  0.2754588034791006,\n",
       "  0.2747790674928208,\n",
       "  0.2747234909887045,\n",
       "  0.2739430586217155,\n",
       "  0.27340189818765076,\n",
       "  0.2732516048659741,\n",
       "  0.27279761811377295,\n",
       "  0.2722293495292395,\n",
       "  0.2718235502990199,\n",
       "  0.2712420661684493,\n",
       "  0.27104140335405374,\n",
       "  0.27052598100312997,\n",
       "  0.2697451582676928,\n",
       "  0.2691567510786191,\n",
       "  0.2689983366240918,\n",
       "  0.268786329618642,\n",
       "  0.26823885633911887,\n",
       "  0.26759867642966795,\n",
       "  0.26728876375816235,\n",
       "  0.26674897276179893,\n",
       "  0.26670323564133175,\n",
       "  0.26599749649914217,\n",
       "  0.26540642389109437,\n",
       "  0.2650634373577548,\n",
       "  0.2645189627795152,\n",
       "  0.26429014873336737,\n",
       "  0.26353928425782164,\n",
       "  0.26313126464964637,\n",
       "  0.26276940611046806,\n",
       "  0.2623112659219285,\n",
       "  0.26199167442153876,\n",
       "  0.26138827372604695,\n",
       "  0.2608229291271156,\n",
       "  0.2606939652436216,\n",
       "  0.2603870382611181,\n",
       "  0.26009940030709117,\n",
       "  0.25907436516922966,\n",
       "  0.2589793696369923,\n",
       "  0.25868894894358135,\n",
       "  0.25820457494594684,\n",
       "  0.25749327704100544,\n",
       "  0.2572195515246459,\n",
       "  0.2567141832600177,\n",
       "  0.2565041566398782,\n",
       "  0.2560173193333854,\n",
       "  0.25564835210081555,\n",
       "  0.25520273749257477,\n",
       "  0.25480542909091625,\n",
       "  0.2543509008598999,\n",
       "  0.2542322399750562,\n",
       "  0.25356537775254584,\n",
       "  0.25292391613335674,\n",
       "  0.2526892339679557,\n",
       "  0.2520373129928616,\n",
       "  0.25188050891312075,\n",
       "  0.2513598531064853,\n",
       "  0.2511411514920248,\n",
       "  0.2505680587090237,\n",
       "  0.2501738201564466,\n",
       "  0.24960074668199245,\n",
       "  0.24935446532679276,\n",
       "  0.24885164096321857,\n",
       "  0.2487353648937924,\n",
       "  0.24830175453508405,\n",
       "  0.24773100312326995,\n",
       "  0.24741129682097637,\n",
       "  0.24696285959700465,\n",
       "  0.24661231376755405,\n",
       "  0.24648517915900325,\n",
       "  0.24622672061685105,\n",
       "  0.24545302819198286,\n",
       "  0.24497990520067617,\n",
       "  0.24433847191468092,\n",
       "  0.24405707251018202,\n",
       "  0.24389743091354907,\n",
       "  0.24378993855395786,\n",
       "  0.24320253603894945,\n",
       "  0.24267348898968227,\n",
       "  0.24199299136517752,\n",
       "  0.24205656286696314,\n",
       "  0.24129192384196,\n",
       "  0.2411897106909416,\n",
       "  0.24053239864362796,\n",
       "  0.24028483054167787,\n",
       "  0.23999681565123546,\n",
       "  0.23944623495491457,\n",
       "  0.23933318005481236,\n",
       "  0.23893870266390518,\n",
       "  0.2383528599436854,\n",
       "  0.23798511670508854,\n",
       "  0.2375994278511531,\n",
       "  0.2372719599327571,\n",
       "  0.23675652247079662,\n",
       "  0.23657253279652393,\n",
       "  0.23604389122674163,\n",
       "  0.23554154223119708,\n",
       "  0.23530570617024327,\n",
       "  0.23506546314333526,\n",
       "  0.23433441091591203,\n",
       "  0.23415512182343173,\n",
       "  0.2338982404957355,\n",
       "  0.23364099881178896,\n",
       "  0.2331518249612459,\n",
       "  0.23287510137322923,\n",
       "  0.23238384996501493,\n",
       "  0.23186579430607004,\n",
       "  0.2315732223886839,\n",
       "  0.2314173465883228,\n",
       "  0.23084634248639496,\n",
       "  0.23057834573195013,\n",
       "  0.2299146918763577,\n",
       "  0.22983444408631662,\n",
       "  0.22929461950987157,\n",
       "  0.22897663082874997,\n",
       "  0.2287558480887346,\n",
       "  0.22822319873621766,\n",
       "  0.22807526294614228,\n",
       "  0.22766373652807423,\n",
       "  0.22710783401845205,\n",
       "  0.22706162215958178,\n",
       "  0.22669859923107524,\n",
       "  0.2260190296760747,\n",
       "  0.22581228550890803,\n",
       "  0.2252186761355736,\n",
       "  0.22493151753721102,\n",
       "  0.22465398403960216,\n",
       "  0.22414132448988902,\n",
       "  0.2239738406849579,\n",
       "  0.22371169043258882,\n",
       "  0.22315430389323704,\n",
       "  0.2226912305808403,\n",
       "  0.22266143140658526,\n",
       "  0.22218563942842082,\n",
       "  0.22195686798700145,\n",
       "  0.2216832547540396,\n",
       "  0.2211230842160507,\n",
       "  0.2210091490980605,\n",
       "  0.22054051891179152,\n",
       "  0.21998488882058104,\n",
       "  0.21985737454723303,\n",
       "  0.21950319934059198,\n",
       "  0.2192704480298808,\n",
       "  0.21882749905048962,\n",
       "  0.21834001763605734,\n",
       "  0.21818672162546238,\n",
       "  0.21754500311864933,\n",
       "  0.21763467494870575,\n",
       "  0.2170940037344543,\n",
       "  0.21673510716834538,\n",
       "  0.21635190156144155,\n",
       "  0.21602599448721174,\n",
       "  0.21580425618400037,\n",
       "  0.21515163905184034,\n",
       "  0.21493976678646787,\n",
       "  0.214564248499736,\n",
       "  0.21442974768054318,\n",
       "  0.2139054599782111,\n",
       "  0.21361172828875796,\n",
       "  0.21317335732386145,\n",
       "  0.21292398723078446,\n",
       "  0.21259075130375338,\n",
       "  0.21215235053653447,\n",
       "  0.21190215059569184,\n",
       "  0.21155998845335464,\n",
       "  0.21133220804409242,\n",
       "  0.21080571434027712,\n",
       "  0.21060405167895305,\n",
       "  0.2101803010618183,\n",
       "  0.20974873321157106,\n",
       "  0.2096843161213566],\n",
       " 'accuracy': [0.51760566,\n",
       "  0.4964789,\n",
       "  0.51760566,\n",
       "  0.5140845,\n",
       "  0.49295774,\n",
       "  0.49295774,\n",
       "  0.50352114,\n",
       "  0.48943663,\n",
       "  0.50352114,\n",
       "  0.51760566,\n",
       "  0.5140845,\n",
       "  0.5316901,\n",
       "  0.5633803,\n",
       "  0.55985916,\n",
       "  0.5669014,\n",
       "  0.5739437,\n",
       "  0.5915493,\n",
       "  0.5880282,\n",
       "  0.60211265,\n",
       "  0.62676054,\n",
       "  0.62323946,\n",
       "  0.65140843,\n",
       "  0.66549295,\n",
       "  0.66549295,\n",
       "  0.6619718,\n",
       "  0.6619718,\n",
       "  0.67253524,\n",
       "  0.6830986,\n",
       "  0.6830986,\n",
       "  0.6866197,\n",
       "  0.6866197,\n",
       "  0.6866197,\n",
       "  0.693662,\n",
       "  0.6971831,\n",
       "  0.7077465,\n",
       "  0.71478873,\n",
       "  0.7077465,\n",
       "  0.7112676,\n",
       "  0.71478873,\n",
       "  0.7112676,\n",
       "  0.7183099,\n",
       "  0.72183096,\n",
       "  0.71478873,\n",
       "  0.7183099,\n",
       "  0.72887325,\n",
       "  0.72183096,\n",
       "  0.7359155,\n",
       "  0.7394366,\n",
       "  0.7394366,\n",
       "  0.74647886,\n",
       "  0.75,\n",
       "  0.7429578,\n",
       "  0.75352114,\n",
       "  0.74647886,\n",
       "  0.7429578,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75352114,\n",
       "  0.75352114,\n",
       "  0.7605634,\n",
       "  0.7605634,\n",
       "  0.7640845,\n",
       "  0.7570422,\n",
       "  0.7640845,\n",
       "  0.7640845,\n",
       "  0.76760566,\n",
       "  0.7640845,\n",
       "  0.77112675,\n",
       "  0.7746479,\n",
       "  0.7746479,\n",
       "  0.7640845,\n",
       "  0.76760566,\n",
       "  0.7746479,\n",
       "  0.77112675,\n",
       "  0.7887324,\n",
       "  0.7746479,\n",
       "  0.7816901,\n",
       "  0.7816901,\n",
       "  0.78521127,\n",
       "  0.78521127,\n",
       "  0.7746479,\n",
       "  0.78521127,\n",
       "  0.7887324,\n",
       "  0.7887324,\n",
       "  0.7922535,\n",
       "  0.7887324,\n",
       "  0.79577464,\n",
       "  0.79577464,\n",
       "  0.79577464,\n",
       "  0.79577464,\n",
       "  0.806338,\n",
       "  0.806338,\n",
       "  0.7992958,\n",
       "  0.7992958,\n",
       "  0.8028169,\n",
       "  0.806338,\n",
       "  0.806338,\n",
       "  0.80985916,\n",
       "  0.8028169,\n",
       "  0.8028169,\n",
       "  0.80985916,\n",
       "  0.8169014,\n",
       "  0.80985916,\n",
       "  0.8133803,\n",
       "  0.80985916,\n",
       "  0.80985916,\n",
       "  0.8169014,\n",
       "  0.8133803,\n",
       "  0.8239437,\n",
       "  0.8239437,\n",
       "  0.82042253,\n",
       "  0.8239437,\n",
       "  0.82746476,\n",
       "  0.82042253,\n",
       "  0.82746476,\n",
       "  0.8239437,\n",
       "  0.82746476,\n",
       "  0.8239437,\n",
       "  0.8239437,\n",
       "  0.82746476,\n",
       "  0.8309859,\n",
       "  0.82746476,\n",
       "  0.8309859,\n",
       "  0.82746476,\n",
       "  0.83450705,\n",
       "  0.8309859,\n",
       "  0.8309859,\n",
       "  0.8309859,\n",
       "  0.8309859,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.8380282,\n",
       "  0.8380282,\n",
       "  0.83450705,\n",
       "  0.83450705,\n",
       "  0.8380282,\n",
       "  0.8380282,\n",
       "  0.8380282,\n",
       "  0.8380282,\n",
       "  0.8415493,\n",
       "  0.8380282,\n",
       "  0.8415493,\n",
       "  0.8415493,\n",
       "  0.8450704,\n",
       "  0.8415493,\n",
       "  0.8415493,\n",
       "  0.8415493,\n",
       "  0.8380282,\n",
       "  0.84859157,\n",
       "  0.8450704,\n",
       "  0.8450704,\n",
       "  0.8415493,\n",
       "  0.8415493,\n",
       "  0.8450704,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.8415493,\n",
       "  0.8415493,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.8450704,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.8556338,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.8556338,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.8450704,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.8450704,\n",
       "  0.8450704,\n",
       "  0.8450704,\n",
       "  0.84859157,\n",
       "  0.8450704,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.8450704,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.8556338,\n",
       "  0.84859157,\n",
       "  0.84859157,\n",
       "  0.8556338,\n",
       "  0.84859157,\n",
       "  0.8556338,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.84859157,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.85211265,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.85211265,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.85211265,\n",
       "  0.85915494,\n",
       "  0.8556338,\n",
       "  0.85915494,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.8556338,\n",
       "  0.85915494,\n",
       "  0.8556338,\n",
       "  0.85915494,\n",
       "  0.8626761,\n",
       "  0.85915494,\n",
       "  0.8556338,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.8626761,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.85915494,\n",
       "  0.8556338,\n",
       "  0.85915494,\n",
       "  0.8626761,\n",
       "  0.86619717,\n",
       "  0.8626761,\n",
       "  0.8626761,\n",
       "  0.8626761,\n",
       "  0.8626761,\n",
       "  0.86619717,\n",
       "  0.8697183,\n",
       "  0.86619717,\n",
       "  0.85915494,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.85915494,\n",
       "  0.86619717,\n",
       "  0.86619717,\n",
       "  0.8697183,\n",
       "  0.8697183,\n",
       "  0.8626761,\n",
       "  0.86619717,\n",
       "  0.86619717,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.87323946,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.8697183,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.87676054,\n",
       "  0.8697183,\n",
       "  0.87323946,\n",
       "  0.87323946,\n",
       "  0.87676054,\n",
       "  0.87676054,\n",
       "  0.8802817,\n",
       "  0.87323946,\n",
       "  0.8802817,\n",
       "  0.87676054,\n",
       "  0.87323946,\n",
       "  0.87676054,\n",
       "  0.87676054,\n",
       "  0.87676054,\n",
       "  0.87676054,\n",
       "  0.87676054,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.87676054,\n",
       "  0.8802817,\n",
       "  0.87676054,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.87676054,\n",
       "  0.87676054,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.88380283,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.8802817,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.8802817,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.8802817,\n",
       "  0.8802817,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.8802817,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.8873239,\n",
       "  0.8873239,\n",
       "  0.88380283,\n",
       "  0.88380283,\n",
       "  0.8873239,\n",
       "  0.8873239,\n",
       "  0.8873239,\n",
       "  0.8873239,\n",
       "  0.88380283,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.8873239,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.8873239,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.8943662,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.8943662,\n",
       "  0.89084506,\n",
       "  0.8943662,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89084506,\n",
       "  0.89788735,\n",
       "  0.89788735,\n",
       "  0.8943662,\n",
       "  0.89788735,\n",
       "  0.89788735,\n",
       "  0.89084506,\n",
       "  0.89788735,\n",
       "  0.8943662,\n",
       "  0.8943662,\n",
       "  0.89788735,\n",
       "  0.8943662,\n",
       "  0.89788735,\n",
       "  0.90140843,\n",
       "  0.89788735,\n",
       "  0.89788735,\n",
       "  0.8943662,\n",
       "  0.89788735,\n",
       "  0.8943662,\n",
       "  0.89788735,\n",
       "  0.89788735,\n",
       "  0.8943662,\n",
       "  0.89788735,\n",
       "  0.90140843,\n",
       "  0.89788735,\n",
       "  0.89788735,\n",
       "  0.90140843,\n",
       "  0.90140843,\n",
       "  0.89788735,\n",
       "  0.90140843,\n",
       "  0.90140843,\n",
       "  0.90140843,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.90140843,\n",
       "  0.9049296,\n",
       "  0.90140843,\n",
       "  0.9049296,\n",
       "  0.90140843,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9049296,\n",
       "  0.9084507,\n",
       "  0.9084507,\n",
       "  0.9084507,\n",
       "  0.9049296,\n",
       "  0.9084507,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9084507,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9084507,\n",
       "  0.91549295,\n",
       "  0.9084507,\n",
       "  0.9119718,\n",
       "  0.9084507,\n",
       "  0.9119718,\n",
       "  0.9084507,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.9119718,\n",
       "  0.91549295,\n",
       "  0.9119718],\n",
       " 'val_loss': [4.418570272546066,\n",
       "  2.936900876697741,\n",
       "  2.8516496457551654,\n",
       "  2.083134200698451,\n",
       "  1.563599543822439,\n",
       "  2.8216432747087983,\n",
       "  1.8746112296455786,\n",
       "  1.0421314139115183,\n",
       "  0.837160084749523,\n",
       "  0.8037553197459171,\n",
       "  0.7835890544088263,\n",
       "  0.7478965326359398,\n",
       "  0.74045275637978,\n",
       "  0.7347277170733402,\n",
       "  0.7290841692372372,\n",
       "  0.7241818791941592,\n",
       "  0.7202356997289155,\n",
       "  0.716758592505204,\n",
       "  0.7139716462085122,\n",
       "  0.7114695687043039,\n",
       "  0.7085525305647599,\n",
       "  0.7061022689467982,\n",
       "  0.703890797966405,\n",
       "  0.7018119441835504,\n",
       "  0.6997015532694365,\n",
       "  0.6982980972842167,\n",
       "  0.6961411513780292,\n",
       "  0.6941047022217198,\n",
       "  0.6929235307793868,\n",
       "  0.6911564230918884,\n",
       "  0.6889279528668052,\n",
       "  0.6881319980872305,\n",
       "  0.6867301169194673,\n",
       "  0.6855478142437182,\n",
       "  0.6839932491904811,\n",
       "  0.6833558528046859,\n",
       "  0.6822833832941557,\n",
       "  0.6812485111387152,\n",
       "  0.6796248429699948,\n",
       "  0.6782401605656273,\n",
       "  0.6775418350571081,\n",
       "  0.6771168131577341,\n",
       "  0.6758210803333081,\n",
       "  0.6745540367929559,\n",
       "  0.6742642979872854,\n",
       "  0.6742178095014472,\n",
       "  0.6729031832594621,\n",
       "  0.671820729029806,\n",
       "  0.6707413290676317,\n",
       "  0.6702550693562156,\n",
       "  0.6695257745291058,\n",
       "  0.668737394558756,\n",
       "  0.668519717768619,\n",
       "  0.6685651302337646,\n",
       "  0.6674750309241445,\n",
       "  0.666579102215014,\n",
       "  0.6663774992290296,\n",
       "  0.6662442219884772,\n",
       "  0.6659923522095931,\n",
       "  0.6659367630356237,\n",
       "  0.6656979366352683,\n",
       "  0.6653375374643427,\n",
       "  0.6656986832618713,\n",
       "  0.6654630265737834,\n",
       "  0.6655443298189263,\n",
       "  0.6662182305988512,\n",
       "  0.6656527017292223,\n",
       "  0.6656454036110326,\n",
       "  0.665200884718644,\n",
       "  0.6654249203832526,\n",
       "  0.6647998220042178,\n",
       "  0.6641864055081418,\n",
       "  0.6638431699652421,\n",
       "  0.6633361872873809,\n",
       "  0.6619338826129311,\n",
       "  0.6621535483159517,\n",
       "  0.6619389941817836,\n",
       "  0.6629065607723437,\n",
       "  0.6637338286951968,\n",
       "  0.6638197917687265,\n",
       "  0.6650424191826269,\n",
       "  0.6646910284694872,\n",
       "  0.6656251474430687,\n",
       "  0.6676714828139857,\n",
       "  0.6699025392532348,\n",
       "  0.672672104208093,\n",
       "  0.6748534290414108,\n",
       "  0.6784702175541928,\n",
       "  0.6812744015141537,\n",
       "  0.6897486529852215,\n",
       "  0.7893726035168297,\n",
       "  0.7891129738406131,\n",
       "  0.7885351990398608,\n",
       "  0.7885799627555045,\n",
       "  0.7877428299502323,\n",
       "  0.7881303780957272,\n",
       "  0.7880482523064865,\n",
       "  0.787211665354277,\n",
       "  0.7871218248417503,\n",
       "  0.7873228581328141,\n",
       "  0.7875019443662543,\n",
       "  0.7867345100954959,\n",
       "  0.7864064749918486,\n",
       "  0.7864345174086721,\n",
       "  0.7855244140875967,\n",
       "  0.7857971530211599,\n",
       "  0.7854544068637647,\n",
       "  0.7844906097964237,\n",
       "  0.7844444990158081,\n",
       "  0.7843788529697218,\n",
       "  0.7843972256309107,\n",
       "  0.7842852598742435,\n",
       "  0.7834927358125385,\n",
       "  0.7826523542404175,\n",
       "  0.7817128551633734,\n",
       "  0.7822577319647136,\n",
       "  0.7830257597722505,\n",
       "  0.7829288275618302,\n",
       "  0.7824149865853159,\n",
       "  0.7825809190147801,\n",
       "  0.7815876954480221,\n",
       "  0.7824626238722551,\n",
       "  0.7818727537205344,\n",
       "  0.7820662680425142,\n",
       "  0.7817252949664467,\n",
       "  0.7810697561816166,\n",
       "  0.7805188549192328,\n",
       "  0.7797853494945325,\n",
       "  0.7793657955370451,\n",
       "  0.779174554347992,\n",
       "  0.7801101590457715,\n",
       "  0.7807818312393991,\n",
       "  0.7810374542286521,\n",
       "  0.7819210115231966,\n",
       "  0.7823116471892909,\n",
       "  0.7817697663056223,\n",
       "  0.7814296553009434,\n",
       "  0.7813204319853532,\n",
       "  0.7817280436816968,\n",
       "  0.7822833142782513,\n",
       "  0.7821565747261048,\n",
       "  0.7831333894478647,\n",
       "  0.7840852373524716,\n",
       "  0.783197790070584,\n",
       "  0.7825653584379899,\n",
       "  0.7830926581432945,\n",
       "  0.7822721769935206,\n",
       "  0.7832389279415733,\n",
       "  0.7826380102257979,\n",
       "  0.7835710218078211,\n",
       "  0.7838016936653539,\n",
       "  0.78485780013235,\n",
       "  0.7844335687787909,\n",
       "  0.7845973071299102,\n",
       "  0.7860479210552417,\n",
       "  0.7861699047841524,\n",
       "  0.7868939544025221,\n",
       "  0.7873915433883667,\n",
       "  0.7873424442190873,\n",
       "  0.7870405109305131,\n",
       "  0.7879610343983299,\n",
       "  0.7884912810827557,\n",
       "  0.7885082803274456,\n",
       "  0.7892270263872648,\n",
       "  0.7895017027854919,\n",
       "  0.7892573513482747,\n",
       "  0.7897936940193176,\n",
       "  0.7895125269889831,\n",
       "  0.7899114520926225,\n",
       "  0.7899113855863872,\n",
       "  0.7894147195314106,\n",
       "  0.7911220381134435,\n",
       "  0.7915532758361414,\n",
       "  0.7925231582240054,\n",
       "  0.7925445600559837,\n",
       "  0.7917192346171329,\n",
       "  0.7944667584017704,\n",
       "  0.7955925979112324,\n",
       "  0.7957589720424852,\n",
       "  0.7950785800030357,\n",
       "  0.795029143910659,\n",
       "  0.7941526086706864,\n",
       "  0.7950813262086166,\n",
       "  0.7947542541905454,\n",
       "  0.7955662708533437,\n",
       "  0.7965092056675961,\n",
       "  0.7968427683177747,\n",
       "  0.7966907902767784,\n",
       "  0.7976754150892559,\n",
       "  0.7984368826213636,\n",
       "  0.7982497152529264,\n",
       "  0.797549537608498,\n",
       "  0.7980135346713819,\n",
       "  0.7983931503797832,\n",
       "  0.7976265141838476,\n",
       "  0.7988741153164913,\n",
       "  0.7988487551086827,\n",
       "  0.7989701660055863,\n",
       "  0.7989214539527894,\n",
       "  0.7990084428536265,\n",
       "  0.7998307021040666,\n",
       "  0.8002384148145977,\n",
       "  0.7995850782645376,\n",
       "  0.8008847638180382,\n",
       "  0.8004174364240546,\n",
       "  0.7994542385402479,\n",
       "  0.7997056910866185,\n",
       "  0.8023007229754799,\n",
       "  0.8012889717754564,\n",
       "  0.8020477401582818,\n",
       "  0.8010415472482381,\n",
       "  0.8034516140034325,\n",
       "  0.8022677910955329,\n",
       "  0.8016880581253454,\n",
       "  0.8023814715837178,\n",
       "  0.8033097731439691,\n",
       "  0.8040343447735435,\n",
       "  0.8031273157973039,\n",
       "  0.8030136980508503,\n",
       "  0.8040009134694149,\n",
       "  0.8023820255932055,\n",
       "  0.8018023660308436,\n",
       "  0.8044118856128893,\n",
       "  0.8044055505802757,\n",
       "  0.8059439163458975,\n",
       "  0.8048471952739514,\n",
       "  0.804075328927291,\n",
       "  0.8030231457007558,\n",
       "  0.8041472253046538,\n",
       "  0.8058650813604656,\n",
       "  0.8054287954380638,\n",
       "  0.8062478830939845,\n",
       "  0.8072442387279711,\n",
       "  0.8064125305727908,\n",
       "  0.8104977237550836,\n",
       "  0.8091739704734401,\n",
       "  0.8108857386990598,\n",
       "  0.8114303946495056,\n",
       "  0.8100673343005933,\n",
       "  0.812102831037421,\n",
       "  0.8130722673315751,\n",
       "  0.8139835734116404,\n",
       "  0.813135500330674,\n",
       "  0.8157418163199174,\n",
       "  0.8146628235515795,\n",
       "  0.8127543593707838,\n",
       "  0.813406857691313,\n",
       "  0.8142813939797251,\n",
       "  0.8158791780471801,\n",
       "  0.8167174232633491,\n",
       "  0.8176760880570663,\n",
       "  0.8182834499760678,\n",
       "  0.8170396478552567,\n",
       "  0.8189976165169164,\n",
       "  0.8198741774809988,\n",
       "  0.821242534486871,\n",
       "  0.8213991027129324,\n",
       "  0.8215462778743945,\n",
       "  0.8215477673630965,\n",
       "  0.8206690518479598,\n",
       "  0.8229629428763139,\n",
       "  0.8253630349510594,\n",
       "  0.8276284355866281,\n",
       "  0.8302297115325927,\n",
       "  0.828579969155161,\n",
       "  0.8289882992443286,\n",
       "  0.8322419028533132,\n",
       "  0.8317889094352722,\n",
       "  0.832191853146804,\n",
       "  0.8303090283745214,\n",
       "  0.8343981780503925,\n",
       "  0.8351408418856169,\n",
       "  0.8363894130054274,\n",
       "  0.8362633140463578,\n",
       "  0.8448917934769078,\n",
       "  0.8591460466384888,\n",
       "  0.8592058263326946,\n",
       "  0.8560056146822478,\n",
       "  0.9533911541888588,\n",
       "  0.8883837022279438,\n",
       "  0.9562959024780675,\n",
       "  0.9531690083051982,\n",
       "  0.9529788550577666,\n",
       "  0.9530373617222435,\n",
       "  0.9558109860671195,\n",
       "  0.959394245398672,\n",
       "  0.9555685388414483,\n",
       "  0.9593232575215791,\n",
       "  0.9596349502864637,\n",
       "  0.9600333646724099,\n",
       "  0.959806447907498,\n",
       "  0.9636975790324964,\n",
       "  0.9664228709120499,\n",
       "  0.9670718550682068,\n",
       "  0.9684148669242859,\n",
       "  0.9628670987329985,\n",
       "  0.967241412714908,\n",
       "  0.969530301345022,\n",
       "  0.9753105596492165,\n",
       "  0.9764135084654155,\n",
       "  0.9759203584570634,\n",
       "  1.077557567546242,\n",
       "  1.0775405356758518,\n",
       "  0.9931882939840618,\n",
       "  1.077855960946334,\n",
       "  1.0777420269815545,\n",
       "  1.0771847950784783,\n",
       "  1.0772760842975817,\n",
       "  1.0771324094973111,\n",
       "  1.0775329251038401,\n",
       "  1.0779402757945813,\n",
       "  1.0786008194873207,\n",
       "  1.0790754493914152,\n",
       "  1.0796416019138537,\n",
       "  1.0801542859328421,\n",
       "  1.0797117747758564,\n",
       "  1.079460839221352,\n",
       "  1.0796002839740955,\n",
       "  1.0809139427385832,\n",
       "  1.080012233633744,\n",
       "  1.0808989537389655,\n",
       "  1.0807869710420308,\n",
       "  1.0819219865297016,\n",
       "  1.0835615936078524,\n",
       "  1.0831380706084401,\n",
       "  1.0822986803556744,\n",
       "  1.0836705860338713,\n",
       "  1.0825558022448891,\n",
       "  1.084257772094325,\n",
       "  1.0840256352173654,\n",
       "  1.0827259289590936,\n",
       "  1.0842690191770854,\n",
       "  1.084325663666976,\n",
       "  1.083698534965515,\n",
       "  1.085353203823692,\n",
       "  1.0864360382682399,\n",
       "  1.0865649135489213,\n",
       "  1.0872183486034996,\n",
       "  1.0877012591612967,\n",
       "  1.0876948846013923,\n",
       "  1.0877502504147982,\n",
       "  1.0883161406767996,\n",
       "  1.0880080825404117,\n",
       "  1.0887400953393234,\n",
       "  1.0893301123066952,\n",
       "  1.0885289493360017,\n",
       "  1.0894093739359003,\n",
       "  1.0880657221141614,\n",
       "  1.0891108537975112,\n",
       "  1.0899993218873676,\n",
       "  1.08951602609534,\n",
       "  1.0898100451419228,\n",
       "  1.0895406873602616,\n",
       "  1.088788750297145,\n",
       "  1.0908752215536017,\n",
       "  1.0897329744539763,\n",
       "  1.0904458472603247,\n",
       "  1.0889812318902268,\n",
       "  1.0907933498683728,\n",
       "  1.0900303715153745,\n",
       "  1.0909732843700208,\n",
       "  1.091504777105231,\n",
       "  1.0919664797029998,\n",
       "  1.0932656727339092,\n",
       "  1.093642274956954,\n",
       "  1.0917173987940738,\n",
       "  1.0915108542693288,\n",
       "  1.0922214533153334,\n",
       "  1.092827380330939,\n",
       "  1.0928170480226216,\n",
       "  1.093616879613776,\n",
       "  1.093272072390506,\n",
       "  1.0936797669059353,\n",
       "  1.0961210439079687,\n",
       "  1.0954907316910594,\n",
       "  1.0952670172641152,\n",
       "  1.0948776508632458,\n",
       "  1.0944555470817967,\n",
       "  1.093680789596156,\n",
       "  1.095688035613612,\n",
       "  1.0964341151086907,\n",
       "  1.0958181004775198,\n",
       "  1.0961497181340267,\n",
       "  1.0970197263516879,\n",
       "  1.0963157377744976,\n",
       "  1.096090696987353,\n",
       "  1.0956882200743023,\n",
       "  1.0962938133038973,\n",
       "  1.0967448234558106,\n",
       "  1.0971539999309339,\n",
       "  1.096670140718159,\n",
       "  1.097329844926533,\n",
       "  1.0972955615896927,\n",
       "  1.0966266368564805,\n",
       "  1.0982411334389135,\n",
       "  1.0974057448537726,\n",
       "  1.0974858309093274,\n",
       "  1.0982927648644698,\n",
       "  1.0973093170868724,\n",
       "  1.0986570621791638,\n",
       "  1.0983024986166703,\n",
       "  1.098745514217176,\n",
       "  1.0979286934200085,\n",
       "  1.0986398295352333,\n",
       "  1.0976779059359902,\n",
       "  1.0996517419815064,\n",
       "  1.1002605676651,\n",
       "  1.0998327192507291,\n",
       "  1.100217836781552,\n",
       "  1.100061519522416,\n",
       "  1.0991395498576917,\n",
       "  1.0998753183766414,\n",
       "  1.1013993840468557,\n",
       "  1.1029583479228773,\n",
       "  1.1019229801077592,\n",
       "  1.1009025523537084,\n",
       "  1.1001995952505814,\n",
       "  1.102199969793621,\n",
       "  1.101280739432887,\n",
       "  1.1021810933163292,\n",
       "  1.100881700766714,\n",
       "  1.10198049796255,\n",
       "  1.1022496763028597,\n",
       "  1.1023467854449625,\n",
       "  1.103227074522721,\n",
       "  1.1029032180183813,\n",
       "  1.1028383393036691,\n",
       "  1.103446105906838,\n",
       "  1.104386810252541,\n",
       "  1.1053928011342098,\n",
       "  1.1050333236393175,\n",
       "  1.1044519198568243,\n",
       "  1.1035051722275584,\n",
       "  1.104292062709206,\n",
       "  1.1047382003382633,\n",
       "  1.10409239844272,\n",
       "  1.1060778530020463,\n",
       "  1.1067675477580021,\n",
       "  1.1076195214924058,\n",
       "  1.1061629282800776,\n",
       "  1.107656572994433,\n",
       "  1.1080276652386314,\n",
       "  1.1080153804076345,\n",
       "  1.1089537884059706,\n",
       "  1.1082322923760666,\n",
       "  1.1082833403035215,\n",
       "  1.110508528508638,\n",
       "  1.110205814712926,\n",
       "  1.1079340244594373,\n",
       "  1.1088706920021458,\n",
       "  1.1083593456368697,\n",
       "  1.1103916230954622,\n",
       "  1.1097993662482815,\n",
       "  1.111262311433491,\n",
       "  1.1103837050889667,\n",
       "  1.110879221715425,\n",
       "  1.1113276782788728,\n",
       "  1.1114241712971737,\n",
       "  1.1129528760910035,\n",
       "  1.1129737753617137,\n",
       "  1.1127684404975489,\n",
       "  1.1135305116051122,\n",
       "  1.1133989773298565,\n",
       "  1.1133114551243029,\n",
       "  1.112994160150227,\n",
       "  1.1136570127386796,\n",
       "  1.1142279123005114,\n",
       "  1.1150116907922845,\n",
       "  1.1151591526834588,\n",
       "  1.1136012579265393,\n",
       "  1.1150450229644775,\n",
       "  1.1155304331528513,\n",
       "  1.1169846999017816,\n",
       "  1.1158975839614869,\n",
       "  1.1147715844606099,\n",
       "  1.1157338154943366,\n",
       "  1.1179510091480456,\n",
       "  1.1168938599134746,\n",
       "  1.1169462203979492,\n",
       "  1.1190046072006226,\n",
       "  1.117138385772705,\n",
       "  1.1163310577994898,\n",
       "  1.11783691079993,\n",
       "  1.1169555651514154,\n",
       "  1.11850264825319,\n",
       "  1.1174865772849636,\n",
       "  1.1197432241941754,\n",
       "  1.1194133921673424,\n",
       "  1.1208317367654097,\n",
       "  1.1205887292560779,\n",
       "  1.120320469454715,\n",
       "  1.120662464593586,\n",
       "  1.1207694743808947,\n",
       "  1.1195813040984304,\n",
       "  1.1208062372709575,\n",
       "  1.1212720067877517,\n",
       "  1.1205505245610288,\n",
       "  1.1210839058223523,\n",
       "  1.1229115862595407,\n",
       "  1.1216392002607647],\n",
       " 'val_accuracy': [0.5473684,\n",
       "  0.51578945,\n",
       "  0.5368421,\n",
       "  0.43157893,\n",
       "  0.4526316,\n",
       "  0.42105263,\n",
       "  0.4631579,\n",
       "  0.4631579,\n",
       "  0.50526315,\n",
       "  0.50526315,\n",
       "  0.51578945,\n",
       "  0.49473685,\n",
       "  0.49473685,\n",
       "  0.49473685,\n",
       "  0.51578945,\n",
       "  0.5263158,\n",
       "  0.5263158,\n",
       "  0.5263158,\n",
       "  0.51578945,\n",
       "  0.50526315,\n",
       "  0.51578945,\n",
       "  0.5368421,\n",
       "  0.5368421,\n",
       "  0.5368421,\n",
       "  0.5368421,\n",
       "  0.5368421,\n",
       "  0.5368421,\n",
       "  0.5368421,\n",
       "  0.5263158,\n",
       "  0.5368421,\n",
       "  0.55789477,\n",
       "  0.5473684,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.56842107,\n",
       "  0.57894737,\n",
       "  0.57894737,\n",
       "  0.57894737,\n",
       "  0.57894737,\n",
       "  0.56842107,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.56842107,\n",
       "  0.55789477,\n",
       "  0.55789477,\n",
       "  0.57894737,\n",
       "  0.58947366,\n",
       "  0.58947366,\n",
       "  0.57894737,\n",
       "  0.57894737,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.57894737,\n",
       "  0.58947366,\n",
       "  0.58947366,\n",
       "  0.58947366,\n",
       "  0.58947366,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6421053,\n",
       "  0.6421053,\n",
       "  0.6421053,\n",
       "  0.6526316,\n",
       "  0.6421053,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6315789,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6210526,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263,\n",
       "  0.6105263]}"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
